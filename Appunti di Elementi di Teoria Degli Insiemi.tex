\documentclass[11pt]{scrartcl}
\usepackage[italian]{babel}
\usepackage[sexy]{evan} %evan.sty
\usepackage{caption}
\usepackage{stmaryrd}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% BOOST SOFTWARE LICENSE - VERSION 1.0 - 17 AUGUST 2003
%
% Copyright (c) 2022 Evan Chen [evan at evanchen.cc]
% https://web.evanchen.cc/ || github.com/vEnhance
%
% Available for download at:
% https://github.com/vEnhance/dotfiles/blob/main/texmf/tex/latex/evan/evan.sty
%
% Permission is hereby granted, free of charge, to any person or organization
% obtaining a copy of the software and accompanying documentation covered by
% this license (the "Software") to use, reproduce, display, distribute,
% execute, and transmit the Software, and to prepare derivative works of the
% Software, and to permit third-parties to whom the Software is furnished to
% do so, all subject to the following:
%
% The copyright notices in the Software and this entire statement, including
% the above license grant, this restriction and the following disclaimer,
% must be included in all copies of the Software, in whole or in part, and
% all derivative works of the Software, unless such copies or derivative
% works are solely in the form of machine-executable object code generated by
% a source language processor.
%
% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
% FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
% SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
% FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
% ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
% DEALINGS IN THE SOFTWARE.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\title{Elementi Di Teoria Degli Insiemi}
\subtitle{\large\normalfont\rmfamily\scshape APPUNTI DEL CORSO DI ELEMENTI DI TEORIA DEGLI INSIEMI \\ TENUTO DAL PROF. MARCELLO MAMINO}
\author{Diego Monaco \\ \textnormal{\href{d.monaco2@studenti.unipi.it}{d.monaco2@studenti.unipi.it}} \\ Università di Pisa}
\date{Anno Accademico 2022-23}
\maketitle
\newpage

\tableofcontents
\eject
\newpage

\section*{Premessa}
Queste dispense sono la quasi esatta trascrizione in \LaTeX\,delle dispense del corso di Elementi di teoria degli insiemi, tenuto dal prof. Marcello Mamino nell'anno accademico 2022-23.

\section*{Ringraziamenti}
Francesco Sorce.

\mbox{}
\vfill
\begin{wrapfigure}{R}{0.2\textwidth}
	\centering
	\href{https://creativecommons.org/licenses/by-nc/4.0/deed.it}{\includegraphics[width=0.2\textwidth]{licenza.png}}
\end{wrapfigure}

Quest'opera è stata rilasciata con licenza Creative Commons Attribuzione - Condividi allo stesso modo 4.0 Internazionale. Per leggere
una copia della licenza visita il sito web \href{http://creativecommons.org/licenses/by-sa/4.0/deed.it}{\textcolor{blue}{https://creativecommons.org/licenses/by-nc/4.0/deed.it}}.\\

\newpage

\newpage
\section{Prologo nel XIX secolo}
La nascita della teoria degli insiemi è una storia complicata di cui so pochissimo. Però, persone che ne sanno molto più di me hanno sostenuto l'opinione che il problema seguente
abbia avuto un ruolo. Come che sia, è almeno un'introduzione possibile.

\begin{problem}
Data una serie trigonometrica:
\[ S(x) = c_0 + \sum_{i=1}^{+\infty}a_i\sin{(ix)}+b_i\cos{(ix)}
	\]
se, per ogni $x \in \RR$, sappiamo che $S(x)$ converge a 0, possiamo dire che i coefficienti $c_0,a_i,b_i$ sono tutti 0?
\end{problem}

Risolto positivamente da \href{https://it.wikipedia.org/wiki/Georg_Cantor}{\textcolor{purple}{Georg Cantor}} nel 1870.

\begin{definition}
Diciamo che $X \subseteq \RR$ è un \vocab{insieme di unicità} se, per ogni serie trigonometrica:
\[ S(x) = c_0 + \sum_{i=1}^{+\infty}a_i\sin{(ix)}+b_i\cos{(ix)}
	\]
vale la seguente implicazione:
\[ \text{$S(x)$ converge a 0 per tutti gli $x\not\in X$} \implies \text{tutti i coefficienti $c_0,a_i,b_i$ sono nulli}
	\]
\end{definition}

\begin{example}
	Per il risultato di Cantor, $\emptyset$ è di unicità.
\end{example}

\begin{problem}
	Quali sottoinsiemi di $\RR$ sono di unicità?
\end{problem}

\begin{fact}
\label{unicità}
$X \subseteq \RR$ è di unicità se (ma non solo se) ogni funzione continua $f : \RR \longrightarrow \RR$ che soddisfi le ipotesi seguenti è necessariamente lineare\footnote{$f(x) = \alpha x + \beta$.}:
\begin{itemize}
	\item per ogni intervallo aperto $\left]a,b\right[$ con $]a,b[ \cap X = \emptyset$, $f_{|\left]a,b\right[}$ è lineare;
	\item per ogni $x \in \RR$, se $f$ ha derivate destre e sinistre in $x$, allora queste coincidono\footnote{Ovvero $f$ non ha punti angolosi.}.
\end{itemize}
\end{fact}

\begin{example}
	$X = \{\ldots,a_{-2},a_{-1},a_0,a_1,a_2,\ldots\} = \{a_i | i \in \ZZ\}$ con $\ldots < a_{-2} < a_{-1} < a_0 < a_1 < a_2 <\ldots$, $\displaystyle\lim_{i \to +\infty} a_i = +\infty$, $\displaystyle\lim_{i \to -\infty} a_i = -\infty$ ha la 
	proprietà data dal \hyperref[unicità]{Fatto 1.5}, quindi è di unicità.
\end{example}

\begin{notexample}
L'intervallo $[0,1]$ o $\RR$ non hanno la proprietà espressa dall'\hyperref[unicità]{Fatto 1.5}.
\end{notexample}

\begin{notexampleb}
Per l'\vocab{insieme di Cantor} non vale il \hyperref[unicità]{Fatto 1.5}.
\end{notexampleb}

Possiamo costruire l'insieme di Cantor a partire dall'intervallo $C_0 = [0,1]$ nel seguente modo:

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=12.5cm]{immagini/cantor.png}
	\end{figure}
\end{center}

ovvero, preso l'intervallo $[0,1]$ possiamo dividerlo in tre parti e rimuovere la parte centrale $\displaystyle\left]\frac 13, \frac 23\right[$, chiamiamo gli intervalli rimanenti $C_1$, possiamo iterare il procedimento sui due segmenti di $C_1$ ed ottenere $C_2,C_3,\ldots$, a questo punto 
definiamo l'insieme di Cantor $C$ come:
\[ C := \bigcap_{i \in \NN}C_i
	\]
Esiste una funzione continua (e crescente) $f : \RR \longrightarrow \RR$ detta \vocab{scala di Cantor} (o \vocab{scala del diavolo}), tale che $f^{\prime}(x) = 0$ per $x \not\in C$ e non è 
derivabile in $x \in C$.

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=13.5cm]{immagini/scalacantor.png}
	\end{figure}
\end{center}

tale funzione si costruisce aggiungendo tratti costanti (prima $\displaystyle\frac 12$, poi $\displaystyle\frac 14$, $\displaystyle\frac 34$ e così via, dividendo l'intervallo $[0,1]$ sull'asse delle ordinate in parti uguali) alle parti eliminate sull'intervallo
$[0,1]$ sull'asse delle ascisse per costruire l'insieme di Cantor.

\begin{note}
Per $\QQ$ e $C$ non vale il \hyperref[unicità]{Fatto 1.5} ma, in realtà, sono di unicità.
\end{note}

\begin{exampleb}
L'insieme degli elementi di una successione crescente col suo limite è un esempio di insieme di unicità.
\end{exampleb}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/succunic.png}
	\end{figure}
\end{center}

Dimostriamo quindi che $X$ è un insieme di unicità.
\begin{proof}
La funzione $f$ è lineare in $]-\infty, a_0[, ]a_0,a_1[, ]a_1,a_2[, \ldots$. Quindi nei punti $a_0,a_1,a_2,\ldots$ ammette derivata destra e sinistra. 
Siccome questi punti non possono essere angolosi, $f_{|]-\infty, a_0[}$, $f_{|]a_0,a_1[}$, etc. hanno lo stesso coefficiente angolare, quindi, sfruttando la cardinalità, $f_{|]-\infty, a_0[}$
è lineare. Siccome $f_{|]-\infty, a_0[}$ è lineare, usando nuovamente l'assenza di punti angolosi abbiamo la tesi.
\end{proof}

\begin{examplebb}
L'insieme degli elementi di una successione crescente di successioni crescenti è un insieme di unicità.
\end{examplebb}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=12.5cm]{immagini/succunic2.png}
	\end{figure}
\end{center}

Dimostriamo che $X$ è di unicità.
\begin{proof}
In ciascuno degli intervalli $]a_{i0}, a_{(i+1)0}[$, $f$ è lineare, ragionando come nell'esempio precedente, ci siamo ridotti alla situazione
- di nuovo - dell'esempio precedente con $a_i^{\prime} = a_{i0}$.
\end{proof}

\subsection{Digressione: insiemi numerabili}
\begin{definition}
	Un insieme $X$ è \vocab{numerabile} se è il supporto di una successione, $X = \{a_0,a_1,a_2,\ldots\} = \{a_i | i \in \NN\}$, con $a_i \ne a_j$ per ogni $i \ne j$.\footnote{O in altre parole se esiste $f : \NN \longrightarrow X$ biunivoca.}
\end{definition}

\begin{example}
	Alcuni esempi di insiemi numerabili sono:
	\begin{itemize}
		\item $\NN$, l'insieme dei numeri naturali, infatti, la successione $a_i = i$ realizza la bigezione.
		\item I numeri dispari, con la bigezione data da $a_i = 2i + 1$.
		\item I numeri primi, $a_i = p_i$, con $p_i$ $i$-esimo numero primo.
		\item $\ZZ$ l'insieme dei numeri interi, con la bigezione data da $a_i = \displaystyle (-1)^i \left\lceil\frac{i}{2}\right\rceil$.
	\end{itemize}
\end{example}

\begin{examplem}
L'insieme $\NN \times \NN = \{(x,y) | x,y \in \NN\}$ è numerabile.
\end{examplem}

\begin{proof}
La funzione $f : \NN \times \NN \longrightarrow \NN : (x,y) \longmapsto 2^x(1+2y) - 1$ è biunivoca (perché?), quindi $a_i = f^{-1}(i)$ enumera $\NN \times \NN$.
\end{proof}

\begin{proposition}
Un sottoinsieme infinito di un insieme numerabile è, a sua volta, numerabile.
\end{proposition}

\begin{proof}
Sia $Y \subseteq X$ con $Y$ infinito e $X = \{a_i | i \in \NN\}$. La sottosuccessione $b_j = a_{i_j}$ degli $a_*$ che appartengono a $Y$ enumera $Y$. A essere precisi 
bisognerebbe dire esattamente chi sono gli indici $i_j$. Per ricorsione:
\[ i_0 = \min\{i | a_i \in Y\} \qquad i_{j+1} = \min\{i > i_j | a_i \in Y\}
	\]
dove i minimi esistono perché $Y$ non è finito.
\end{proof}

\begin{proposition}
Se $X$ e $Y$ sono numerabili $X \times Y = \{(a,b) | a \in X, b \in Y\}$ è anch'esso numerabile.
\end{proposition}

\begin{proof}
Fissiamo $X = \{a_i | i \in \NN\}$, $Y = \{b_j | j \in \NN\}$. Siccome $\NN \times \NN$ è numerabile, $\NN \times \NN = \{(i_t,j_t)|t \in \NN\}$.
Quindi $X \times Y = \{(a_{i_t}, a_{j_t}) | t \in \NN\}$.
\end{proof}

\begin{example}
$\QQ$ è numerabile.
\end{example}

\begin{proof}
$\QQ$ è in corrispondenza biunivoca con:
\[F = \{(\text{num.},\text{den.})\footnote{num. = numeratore, den. = denominatore.} | \text{num. $\in \ZZ$} \wedge \text{den. $\in\NN_{>0}$} \wedge \text{M.C.D.(num.,den.) = 1}\} \subseteq \ZZ \times \NN\]
\end{proof}

\begin{notexample}
$\RR$ non è numerabile.
\end{notexample}

\begin{proof}
Supponendo, per assurdo, che $\RR = \{a_i | i \in \NN\}$, cerchiamo un $x \in \RR$ che non compare fra gli $a_i$. Allo scopo, costruiamo la sottosuccessione $a_{i_j}$
definita per ricorrenza da:
\[ i_0 = 0 \qquad i_1 = \min\{i | a_i > a_0\} \qquad i_{j+1} = \min\{i | \, \text{$a_i$ è compreso tra $a_{j-1}$ e $a_j$}\}
	\]
graficamente:

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/RRnum.png}
	\end{figure}
\end{center}

Si vede facilmente (esercizio!) che la successione $\{a_{i_{2k}}\}_k$ è crescente, $\{a_{i_{2k+1}}\}_k$ è decrescente 
e $\displaystyle \lim_{k \to +\infty} a_{i_{2k}} \leq \lim_{k \to +\infty}a_{i_{2k+1}}$. Fissiamo $x$ tale che $\displaystyle \lim_{k \to +\infty} a_{i_{2k}} \leq x \leq \lim_{k \to +\infty} a_{i_{2k+1}}$.
Chiaramente $x$ non è nessuno degli $a_{i_j}$, perché $a_{i_2k} < x < a_{i_{2k+1}}$. Supponiamo $x = a_n$, allora ci sarà $j$ tale che $i_j < n < i_{j+1}$, ma 
questo è assurdo perché allora $x = a_n$ è compreso fra $a_{i_{j-1}}$ e $a_{i_j}$, però $n < i_{j+1}$ contro la minimalità di quest'ultimo.

\begin{exercise}
Completare la dimostrazione nel caso $n < i$.
\end{exercise}

\begin{exercise}
Dimostrare che l'insieme di Cantor $C$ non è numerabile.
\end{exercise}
\end{proof}

\pagebreak
\subsection{Tornando agli insiemi di unicità}

\begin{theorem}
[Cantor-Lebesgue]
\label{CL}
Se $X \subseteq \RR$ è chiuso e numerabile, allora $X$ soddisfa il \hyperref[unicità]{Fatto 1.5}, ed è, quindi, di unicità.
\end{theorem}

La strategia di dimostrazione passa attraverso una definizione.

\begin{definition}
Dato $X \subseteq \RR$, il \vocab{derivato di Cantor-Bendixson} di $X$ è:
\[ X^{\prime} = X \setminus\{\text{punti isolati di $X$}\}
	\]
(dove $a \in X$ è un \vocab{punto di accumulazione} se $\exists \varepsilon > 0 : ]a - \varepsilon, a + \varepsilon[ \cap X = \{a\}$).
\end{definition}

\begin{remark}
Se $X$ è chiuso e per $X^{\prime}$ vale il \hyperref[unicità]{Fatto 1.5}, allora anche per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{remark}

Dimostriamo questo fatto.

\begin{proof}
Occorre dimostrare che se $f$ è continua, lineare, ristretta agli intervalli aperti che non intersecano $X$, e non ha punti angolosi, allora $f$ è
lineare ristretta agli intervalli aperti che non intersecano $X^{\prime}$. Fatto questo, usando l'ipotesi su $X^{\prime}$, $f$ è lineare - abbiamo quindi
mostrato che per $X$ vale \hyperref[unicità]{Fatto 1.5}.\\
Sia $]a,b[ \cap X^{\prime} = \emptyset$, dobbiamo dire che $f_{|]a,b[}$ è lineare. Ci basta dire che per ogni $\varepsilon > 0$, $f_{|[a+\varepsilon, b-\varepsilon]}$ è lineare.
Siccome $]a,b[ \cap X^{\prime} = \emptyset$, $]a,b[ \cap X = \{\text{punti isolati di $X$}\}$. Quindi $[a+\varepsilon, b-\varepsilon] \cap X$ è finito - se così non fosse, avrebbe un punto di accumulazione 
$\alpha$ che non può essere un punto isolato di $X$ (altrimenti si avrebbe un assurdo). Per cui $f_{|[a+\varepsilon, b-\varepsilon]}$ è lineare a tratti, e, siccome non ha punti angolosi, è lineare.
\end{proof}

\begin{corollary}
Sia $X^{(n)} = X^{\prime\prime\ldots\footnote{$n$ volte.}}$. Se $X^{(n)} = \emptyset$ per qualche $n \in \NN$, allora per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{corollary}

\begin{proof}
Induzione su $n$.
\end{proof}

Il guaio è che ci sono chiusi numerabili per cui $X^{(n)} \ne \emptyset$, qualunque sia $n$.

\begin{example}
Vogliamo costruire $X$ chiuso e numerabile tale che $X^{(n)} \ne \emptyset$ per ogni $n \in \NN$. Cominciamo col rivedere alcuni esempi già visti.
\end{example}

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/es1.png}
	\end{figure}
\end{center}

Tutti i punti sono isolati, $X^{\prime} = \emptyset$.

\pagebreak

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/es2.png}
	\end{figure}
\end{center}

``Successione con punto limite". Tutti i punti sono isolati salvo $l$, quindi $X^{\prime} = \{l\}$ e $X^{\prime\prime} = \emptyset$.

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/es3.png}
	\end{figure}
\end{center}

``Successione di successioni", $X^{\prime} = \{a_{10}, a_{20}, \ldots, l\}$, $X^{\prime\prime} = \{l\}$ e $X^{\prime\prime\prime} = \emptyset$.\\
Si vede che possiamo proseguire, in qualche modo, costruendo una successione di successioni di successioni, etc. $n$ volte, $X_n$. Avremo $X_n^{(n)} \ne \emptyset$, $X_n^{(n+1)} = \emptyset$. Ora costruiamo 
$X_{\omega}$ fatto così:

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/esomega.png}
	\end{figure}
\end{center}

È chiaro che, per ogni $n$, $X_\omega^{(n)} \ne \emptyset$. D'altro canto, $X_\omega$ soddisfa il \hyperref[unicità]{Fatto 1.5}, perché $f$ deve essere lineare in ciascuno degli intervalli
$[a_n,a_{n+1}]$, perché $X_{n+1}$ soddisfa il \hyperref[unicità]{Fatto 1.5}, quindi ci si riduce al caso della successione.

\begin{exercise}
Perché $X_\omega$ è numerabile?
\end{exercise}

Ora potremmo pensare che, pazienza se $X_\omega$ non si smonta a furia di derivati, sarà un caso particolare. Però adesso, possiamo fare una successione di insiemi come $X_\omega$, chiamiamola $X_{\omega+1}$, e 
una successione di questi $X_{\omega+2}$, etc.\\
Al diavolo, serve un nuovo corollario!

\begin{corollary}
Se $X^{(n)}$ è di ``tipo $X_\omega$", allora per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{corollary}

Ok, questo corollario copre $X_\omega$, $X_{\omega + 1}$, $X_{\omega + 2}$, ma copre anche $X_{\omega \cdot 2}$?
\pagebreak
\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=14.5cm]{immagini/2omega.png}
	\end{figure}
\end{center}

No: occorre un nuovo corollario.

\begin{corollary}
Se $X^{(n)}$ è di ``tipo $X_{\omega \cdot 2}$", allora per $X$ vale il \hyperref[unicità]{Fatto 1.5}.
\end{corollary}

E poi un altro per $X_{\omega \cdot 3}$, e un altro per $X_{\omega \cdot 4}$, etc.\\
E ora abbiamo finito? No, perché possiamo costruire una nuova successione con $X_{\omega},X_{\omega \cdot 2},X_{\omega \cdot 3}$, etc.\\
Se chiamiamo questa follia $X_{\omega \cdot \omega}$, ecco che si riparte a fare successioni di $X_{\omega \cdot \omega}$. Ora si sarà capito che definiremo
una serie aritmetica di queste cose, per cui potremo fare anche $\omega^\omega$, $\omega^{\omega^{\omega}}$, etc. È questa la soluzione allora?\\
No, ogni sforzo di trovare l'induzione a capo delle induzioni è vano. Se ho $X_{\omega}$, $X_{\omega^\omega}$, $X_{\omega^{\omega^{\omega}}}$, etc., allora,
ecco che faccio una successione con queste cose, la battezzo in qualche modo - ad esempio, $X_{\varepsilon_0}$ - e si riparte!\\
Per smontare ogni possibile insieme chiuso e numerabile occorre un \textbf{nuovo tipo di induzione}, l'\vocab{induzione transfinita}, che è strettamente più potente dell'induzione aritmetica.
Questa tecnica è stata sviluppata da Cantor, forse prendendo le mosse dal problema degli insiemi di unicità, e sarà uno degli argomenti centrali del corso.

\begin{exercise}[per la fine del corso]
Dimostrare il teorema di \hyperref[CL]{Cantor-Lebesgue}.
\end{exercise}

\subsection{Giochi di parole}
Descrivere un oggetto matematico non basta per crearlo. Se bastasse, si incorrerebbe in contraddizioni come queste.
\paragraph*{Paradosso di Russell}\mbox{}\\
Tipicamente le collezioni - uso questa parola perché daremo, al termine ``insieme", un senso tecnico preciso - non sono membro di se stesse: la collezione di 
tutti i numeri primi non è un numero primo. Però ci sono anche collezioni che sono membri di se stessi: per esempio la collezione di tutte le collezioni. Consideriamo:
\[ N = \{\text{collezioni $X$}\, | X \not\in X \}
	\]
la collezione delle collezioni che non sono membri di se stessi - la $N$ sta per collezioni normali. Quindi ci chiediamo se $N \in N$ oppure no? $N \in N$ se e solo se per definizione $N \not \in N$, che è assurdo.\\
Il paradosso di Russell ci dice che, del principio di collezione - ossia l'idea che data una proprietà ben definita $P$ si possa costruire la collezione $\{X | P(X)\}$ - non ci si può fidare.

\paragraph*{Paradosso di Berry}\mbox{}\\
L'italiano annovera un numero finito di parole, è quindi possibile formare solo un numero finito di frasi di meno di centro parole. Alcune di queste descrivono un numero naturale, altre no. Comunque, solo un numero 
finito di numeri naturali può essere descritto con meno di cento parole. Per il principio del minimo, esiste:
\begin{align*}
	h = \text{``il più piccolo numero naturale che l'italiano non può} \\ 
 \text{descrivere con meno di cento parole"}
\end{align*}
Il guaio chiaramente, è che lo abbiamo appena descritto con sedici parole.\\
Quindi non ci si può fidare troppo neppure dell'italiano, o meglio, non è possibile descrivere precisamente cosa sia una descrizione precisa.\\
In conclusione, occorre fissare un linguaggio formale in cui si esprimano le proposizioni della teoria degli insiemi, e occorre fissare un sistema di assiomi, espressi in questo linguaggio, che 
dicano quali costruzioni sono lecite: quali insiemi esistono. Il ruolo della teoria degli insiemi è, poi, di fondare l'edificio della matematica. L'ambizione, quindi, è che il linguaggio e gli assiomi della teoria degli insiemi, 
siano in realtà, il linguaggio e gli assiomi della matematica.

\subsection{Scopi del corso}
Questo corso persegue due obiettivi:
\begin{enumerate}[(1)]
	\item Studiare i \textbf{fondamenti della matematica}, nella forma più comunemente accettata nel XX secolo e fino ad ora, la teoria degli insiemi di 
	\href{https://it.wikipedia.org/wiki/Ernst_Zermelo}{\textcolor{purple}{Zermelo}}-\href{https://it.wikipedia.org/wiki/Adolf_Abraham_Halevi_Fraenkel}{\textcolor{purple}{Fraenkel}} con l'assioma della scelta (ZFC).
	\item Studiare tecniche e strumenti che sono stati sviluppati grazie alla teoria degli insiemi, per esempio: la teoria delle cardinalità, la teoria dei numeri ordinali, l'induzione e la ricorsione transfinita.
\end{enumerate}

In questo corso non ci occupiamo dei modelli della teoria degli insiemi. Mi spiego. Per esempio, in teoria dei gruppi si assiomatizza cosa sia un gruppo, e poi si studia come possano essere fatti i diversi gruppi. In 
teoria degli insiemi si assiomatizza l'universo di tutti gli insiemi, però, per il teorema di incompletezza di \href{https://it.wikipedia.org/wiki/Kurt_G%C3%B6del}{\textcolor{purple}{Gödel}}, questa assiomatizzazione non 
può essere completa. Quindi esistono tanti universi insiemistici possibili. Indagare queste possibilità - i modelli della teoria degli insiemi - è argomento di corsi più avanzati.

\newpage
\section{Il linguaggio della teoria degli insiemi}
Per non incorrere in contraddizione, accettiamo che le sole proposizioni ad avere senso siano quelle esprimibili mediante \vocab{formule insiemistiche}. Le formule si costruiscono ricorsivamente.
\begin{itemize}
	\item Le lettere $a,b,c,\ldots,A,B,C,\ldots,\alpha,\beta,\gamma,\ldots$ rappresentano \vocab{variabili}. I valori delle variabili sono sempre insiemi, e non ci sono altri oggetti salvo gli insiemi.
	\item Le \vocab{formule atomiche} sono:
	\[ \text{variabile = variabile} \qquad \qquad \text{variabile $\in$ variabile}\footnote{\,``appartiene a".}
		\]
	sono formule atomiche $x=y$, $x=x$, $\alpha = C$, e anche $x \in y$, $x \in x$, $\alpha \in C$.
	\item Le formule atomiche si combinano tra loro mediante:
	\begin{itemize}
		\item \vocab{connettivi logici} ovvero il ``non'' la ``e'' e la ``o'' (inclusiva):
		\[ \text{$\neg$ formula} \qquad \text{formula $\land$ formula} \qquad \text{formula $\lor$ formula}
			\]
		quindi ad esempio:
		\begin{flalign*}
			&\neg\Phi \equiv \text{``$\Phi$ è falsa''} &\\
			&\Phi \land \psi \equiv \text{``$\Phi$ e $\psi$ sono entrambe vere''} &\\
			&\Phi \lor \psi \equiv \text{``almeno una fra $\Phi$ e $\psi$ è vera''}
		\end{flalign*}
		\item \vocab{quantificatori} ovvero quello universale ``per ogni'' e quello esistenziale ``esiste'':
		\[ \forall x \, \text{formula} \qquad \exists x \, \text{formula}
			\]
		ad esempio:
		\begin{flalign*}
			&\forall x \, \Phi \equiv \text{``$\Phi$ è vera qualunque sia l'insieme $x$''} &\\
			&\exists x \, \Phi \equiv \text{``c'è un insieme $x$ che fa si che $\Phi$ sia vera''}
		\end{flalign*}
		\begin{exercise}
			Chiaramente varranno $\forall x \, x = x,$ $ \forall x \, \exists y \, x = y,$ $ \neg \exists x \, \forall y \, x = y$.
		\end{exercise}
	\end{itemize}
\end{itemize}

\textbf{\underline{L'intuizione}} è che l'universo insiemistico sia un gigantesco grafo diretto (aciclico) i cui vertici sono gli insiemi,
ed in cui le frecce rappresentano la relazione di appartenenza.

\begin{center}
	\begin{figure}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/graf.png}
	\end{figure}
\end{center}

Possiamo solo fare affermazioni a proposito di vertici e frecce di questo grafo. Per esempio:
\[ \text{``$a$ è un elemento di un elemento di un certo $b$''} \equiv \text{``c'è un percorso di due frecce fra $a$ e $b$''} 
	\]
che corrisponde mediante formule insiemistiche a $ \exists x \, a \in x \land x \in b$. E ancora:
\[\text{``$a$ è un sottoinsieme di $b$''} \equiv \text{``ogni elemento di $a$ è elemento di $b$''} \equiv \]\[
		\equiv\text{``non c'è un insieme che è elemento di $a$ e non di $b$''}\equiv\]\[
	 \equiv \text{``non c'è un vertice con una freccia verso $a$ e non una verso $b$''}
	\]
che corrisponde mediante formule insiemistiche a $\neg\exists x \, x \in a \land \neg x \in b$ (tutto ciò che raggiunge $a$ deve raggiungere anche $b$).\\
\textbf{\underline{Parentesi}} Ad essere precisi, avremmo dovuto definire le formule includendo un mucchio di parentesi, allo scopo di eliminare ogni possibilità
di formare una combinazione di simboli ambigua. Per esempio $\textcolor{red}{\Phi_1 \land \Phi_2 \lor \Phi_3}$ è ambigua, perché si potrebbe leggere $(\Phi_1 \land \Phi_2) \lor \Phi_3$
o $\Phi_1 \land (\Phi_2 \lor \Phi_3)$. In una notazione completamente parentesizzata, per esempio, la formula per ``$a$ è un sottoinsieme di $b$'' sarebbe:
\[ \neg(\exists x((x \in a)\land(\neg(x \in b))))
	\]
Non useremo, in generale, questa notazione, ma useremo le parentesi selettivamente per evitare ambiguità.\\
\textbf{\underline{Abbreviazioni}} Le formule appena descritte costituiscono il linguaggio della teoria degli insiemi \textbf{puro}. Durante il corso estenderemo
più volte questo linguaggio mediante abbreviazioni, che semplicemente rimpiazzano formule più lunghe con scritture convenzionali più compatte, e quindi non alterano 
la potenza espressiva del linguaggio. Vediamo le prime abbreviazioni:
\[ x \ne y \Mydef \neg x = y \footnote{Cioè ``non è vero che $x$ è uguale a $y$''.} \qquad x \not\in y \Mydef \neg x \in y \qquad \not\exists x \,\Phi \Mydef \neg \exists x \, \Phi
	\]\[ \Phi \rightarrow \psi \Mydef \psi \lor \neg \Phi \qquad \Phi \leftrightarrow \psi \Mydef (\Phi \rightarrow \psi) \land (\psi \rightarrow \Phi)
		\]\[ \exists x \in A \; \Phi \Mydef \exists x (x \in A \land \Phi) \qquad \forall x \in A \; \Phi \Mydef \forall x (x \in A \rightarrow \Phi)
			\]\[ \exists !\, x\, \Phi(x) \Mydef \exists x (\Phi(x) \land \forall y(\Phi(y) \rightarrow y = x))
				\]\[ \exists !\, x \in A \,\Phi(x) \Mydef \exists! \, x(x \in A \land \Phi(x))
					\]\[ A \subseteq B \Mydef \forall x (x \in A \rightarrow x \in B) \qquad A \subsetneq B \Mydef( A \subseteq B) \land (A \ne B)
						\]\[ C = A \cup B \Mydef \forall x \, x \in C \leftrightarrow (x \in A \lor x \in B)
							\]\[ C = A \cap B \Mydef \forall x \, x \in C \leftrightarrow (x \in A \land x \in B)
								\]
\begin{note}
	Il fatto che possiamo dire $C = A \cup B$ o $C = A \cap B$ non significa né che questi oggetti esistano né che siano unici. Dimostreremo fra poco l'esistenza e unicità 
	di unione e intersezione.
\end{note}

\begin{exercise}
Esprimi queste proposizioni mediante formule insiemistiche pure:
\begin{itemize}
	\item gli elementi degli elementi di $A$ sono elementi di $A$;
	\item $B$ è l'insieme dei sottoinsiemi di $A$;
	\item l'unione degli elementi di $A$ è l'intersezione di quelli di $B$\footnote{Qui assumi che l'unione e intersezione esistano e siano uniche.}
\end{itemize}
\end{exercise}

\subsection{Le regole di inferenza}
La teoria assiomatica degli insiemi si compone di tre parti: il linguaggio formale che abbiamo appena descritto, gli assiomi della teoria che studieremo durante il corso, 
ed un sistema di regole che specificano precisamente quali passaggi sono leciti nelle dimostrazioni. Possiamo immaginare questa ultima componente come una specie di algebra dei ragionamenti,
che permette di verificare i passaggi di una dimostrazione in maniera puramente meccanica, come se fossero semplici manipolazioni algebrica. Noi non vedremo le regole di inferenza, e voglio spiegare qui il perché.
\begin{enumerate}[1]
	\item Sono argomento del corso di logica.
	\item In realtà, scrivere le dimostrazioni in maniera formale, le renderebbe lunghissime e particolarmente incomprensibili.
	\item In pratica, non si sbaglia facendo ragionamenti che non reggono, si sbaglia dicendo cose fumose che non possono essere espresse nel linguaggio della teoria. Per esempio, le parole ``e così via'' sono pericolose.
	\item Conoscere le regole - fidatevi - non aiuta né a trovare né a capire le dimostrazioni.
\end{enumerate}
Pur senza dare un sistema completo di regole, vediamo qualche manipolazione formale che potrebbe servire.\\
\textbf{\underline{Tavole di verità}} Due combinazioni mediante connettivi logici ($\neg$, $\land$, $\lor$, $\rightarrow$, $\leftrightarrow$)
delle stesse formule - ``\vocab{combinazioni booleane}'' - alle volte, dicono la stessa cosa. Per esempio, $\neg \Phi \lor \neg \psi \equiv\footnote{\,``equivale a''.} \neg (\Phi \land \psi)$.
Per verificare questo fatto basta considerare tutte le possibili combinazioni di valori di verità che possono assumere le formule combinate - nell'esempio $\Phi$ e $\psi$ - compilando una ``\vocab{tabella di verità}''.
\begin{center}
	\begin{tabular}{>{$}l<{$}>{$}l<{$}|*{7}{>{$}l<{$}}}
	\Phi & \psi & \neg\Phi   & \neg\psi   & \neg\Phi \lor \neg\psi   & \Phi \land \psi & \neg(\Phi \land \psi)    \\
	\hline\vrule height 14pt width 0pt
	V & V & F & F & \textcolor{red}{F} & V & \textcolor{red}{F}\\
	V & F & F & V & \textcolor{red}{V} & F & \textcolor{red}{V}\\
	F & V & V & F & \textcolor{red}{V} & F & \textcolor{red}{V}\\
	F & F & V & V & \textcolor{red}{V} & F & \textcolor{red}{V}
	\end{tabular} 
\end{center}
Come si osserva le due colonne corrispondenti ai valori di verità delle nostre formule iniziali hanno gli stessi valori di verità in ogni caso.\\
Conviene tenere a mente alcune delle equivalenze elementari:
\[ \neg\neg \Phi \equiv \Phi \qquad \Phi \land (\psi \lor \Theta) \equiv (\Phi \land \psi) \lor (\Phi \land \Theta) \qquad \Phi \lor (\psi \land \Theta) \equiv (\Phi \lor \psi) \land (\Phi \lor \Theta)
	\]\[ \neg(\Phi \land \psi) \equiv \neg \Phi \lor \neg \psi \qquad \neg(\Phi \lor \psi) = \neg \Phi \land \neg \psi
		\]\[ \Phi \rightarrow \neg \psi \equiv \psi \rightarrow \neg \Phi \qquad \Phi \rightarrow \psi \equiv \neg \psi \rightarrow \neg \Phi
			\]

\begin{exercise}
Dimostrare le equivalenze delle formule elencate sopra.
\end{exercise}

Per quanto riguarda i quantificatori ricordiamo le regole seguenti, che tuttavia non sono esaustive.
\[ \neg\forall x \, \Phi \equiv \exists x \, \neg\Phi \qquad \neg\forall x \, \neg \Phi \equiv \exists x \, \Phi
	\]\[ \neg\exists x \, \Phi \equiv \forall x \, \neg \Phi \qquad \neg \exists x \, \neg \Phi \equiv \forall x \, \Phi
		\]

\begin{exercise}
Convinciti della validità delle equivalenze precedenti.
\end{exercise}

\begin{exercise}
Dimostra che:
\[ \neg \forall x \in A \, \Phi \equiv \exists x \in A \, \neg \Phi \qquad \neg \exists x \in A \, \Phi \equiv \forall x \in A \, \Phi
	\]
\end{exercise}

\begin{exercise}
Dimostra che:
\[ \forall x (x \in A \rightarrow x \in B) \equiv \neg \exists x (x \in A \land \neg x \in B)
	\]
\end{exercise}

\begin{exercise}
Secondo te, la seguente formula è vera?
\[ \forall A ((\exists x \, x \in A) \rightarrow \exists x \in A (x \in B \rightarrow \forall y \in A \, y \in B))
	\]
\end{exercise}

Infine vi sono regole per la relazione di uguaglianza, che dicono, in sostanza, che se $x = y$ allora $x$ e $y$ non sono distinguibili, ossia vale $\Phi(x) \leftrightarrow \Phi(y)$ qualunque sia $\Phi$.
Per quanto ci riguarda, \textbf{se $x = y$ allora $x$ e $y$ sono nomi della stessa cosa}.

\newpage
\section{I primi assiomi}
\subsection{Assiomi dell'insieme vuoto e di estensionalità}
\begin{axiom}
[Assioma dell'insieme vuoto]
\label{ax1}
Esiste un insieme vuoto.
\[ \exists x \; \forall y \; y \not\in x
		\]
\end{axiom}

\begin{note}
Questo assioma non sarebbe strettamente necessario, in quanto potremmo ottenere un insieme vuoto anche come sottoprodotto, per esempio, dell'assioma dell'infinito che vedremo in seguito.
Tuttavia è bello poter partire avendo per le mani almeno un insieme.
\end{note}

\begin{axiom}
[Assioma di estensionalità]
\label{ax2}
Un insieme è determinato dalla collezione dei suoi elementi. Due insiemi coincidono se e solo se hanno i medesimi elementi.
\[ \forall a \; \forall b \; a = b \leftrightarrow \forall x (x \in a \leftrightarrow x \in b)
	\]
\end{axiom}

\begin{exercise}
Dimostra che la freccia $a = b \rightarrow \forall x (x \in a \leftrightarrow x \in b)$, in realtà, segue dal fatto che se $a = b$ allora $a$ e $b$ sono indistinguibili\footnote{Nel senso che abbiamo descritto in precedenza, cioè sono nomi della stessa cosa.}.
\end{exercise}

\textbf{\underline{Convenzione}} Le variabili libere (= non quantificate), se non specificato altrimenti, si intendono quantificate universalmente all'inizio della formula. Per cui possiamo scrivere
l'assioma di estensionalità semplicemente nella forma:
\[ a = b \leftrightarrow \forall x (x \in a \leftrightarrow x \in b)
	\]

\begin{proposition}[Unicità dell'insieme vuoto]
C'è un unico insieme vuoto.
\[ \exists ! \; x \; \forall y \; y \not \in x
	\]
\end{proposition}

\begin{proof}
Consideriamo due insiemi vuoti $x_1$ e $x_2$, ossia supponiamo $\forall y \, y \not\in x_1$, e $\forall y \, y \not \in x_2$. Allora:
\[ \forall y (y \in x_1 \leftrightarrow y \in x_2)
	\]
[sono coimplicate logicamente] perché $y \in x_1$ e $y \in x_2$ sono entrambe necessariamente false. Quindi, per \hyperref[ax2]{estensionalità}, la proposizione sopra è equivalente a $x_1 = x_2$.\\
\emph{Dimostrazione formale.} Questo livello di pedanteria non è necessario, ma, per una volta, proviamo a dimostrare in ogni dettaglio la formula $\exists ! x \, \forall y \, y \not\in x$. Per definizione di $\exists !$, ciò equivale a:
\[ \exists x_1 ((\forall y \, y \not \in x_1) \land \forall x_2 ((\forall y \, y \not \in x_2) \rightarrow x_2 = x_1))
	\]
Per l'\hyperref[ax1]{assioma del vuoto}, $\exists x_1 \, \forall y \, y \not \in x_1$: fissiamo questo $x_1$. Resta da dimostrare che:
\[ (\forall y \, y \not \in x_1) \land \forall x_2(\forall y \, y \not \in x_2) \rightarrow x_2 = x_1
	\]
Per costruzione, $\forall y \, y \not\in x_1$, è vera (avendo fissato $x_1$), quindi resta:
\[ \forall x_2 (\forall y \, y \not \in x_2) \rightarrow x_2 = x_1
	\]
Ora prendiamo un $x_2$ qualunque, dobbiamo dimostrare:
\[ \forall y (y \not \in x_2) \rightarrow x_2 = x_1
	\]
Si danno due casi: o $\forall y (y \not \in x_2)$ è vera o è falsa. Nel secondo caso, l'implicazione è vera per via della tabella di verità. Nel primo abbiamo sia $\forall y \, y \not \in x_1$, [vera] per
costruzione, sia $\forall y \, y \not \in x_2$, [vera] per ipotesi. Quindi, preso un qualunque $y$, $y \in x_1$ e $y \in x_2$ sono entrambe false. La tabella di verità di $\leftrightarrow$ ci dice quindi che vale $y \in x_1 \leftrightarrow y \in x_2$, e, per 
l'arbitrarietà di $y$:
\[ \forall y (y \in x_1 \leftrightarrow y \in x_2)
	\]
Dall'\hyperref[ax2]{assioma di estensionalità}:
\[ \forall y (y \in x_1 \leftrightarrow y \in x_2) \rightarrow x_1 = x_2
	\]
Abbiamo quindi $x_1 = x_2$, da cui segue la verità dell'implicazione iniziale.
\end{proof}

Chiaramente, ho voluto scrivere questa dimostrazione delirante per convincervi che NON È UNA BUONA IDEA.

\begin{notation}
L'unicità dell'insieme vuoto ci giustifica ad introdurre una nuova abbreviazione:
\[ x = \emptyset \Mydef \forall y \, y \not\in x \qquad \emptyset \in x \Mydef \exists z (z = \emptyset \land z \in x)
	\]
\end{notation}

\subsection{Assioma di separazione}
\begin{axiom}
[Assioma di separazione]
\label{ax3}
Se $A$ è un insieme, e $\psi(x)$ una formula insiemistica qualunque, allora $\{x \in A | \psi (x)\}$\footnote{Stiamo usando già questa notazione, ma la definiremo a breve.} è un insieme.
\[ \forall A \; \exists B \; \forall x \; x \in B \leftrightarrow (x \in A \land \psi (x))
	\]
\end{axiom}

\begin{note}
Tecnicamente l'assioma di separazione è uno \vocab{schema di assiomi}, ossia una regola che, per ogni possibile formula $\psi$, ci permette di scrivere un assioma.
\end{note}

\begin{proposition}
Fissati $A$ e $\psi(x)$, l'insieme $\{x \in A | \psi(x)\}$ è univocamente definito. Ossia:
\[ \forall A \; \exists \textcolor{red}{!} B \; \forall x \; x \in B \leftrightarrow (x \in A \land \psi(x))
	\]
\end{proposition}

\begin{proof}
Come per l'unicità dell'insieme vuoto, supponiamo di avere $B_1$ e $B_2$ tali che:
\[ \forall x \, x \in B_1 \leftrightarrow (x \in A \land \psi(x)) \qquad \forall x \, x \in B_2 \leftrightarrow (x \in A \land \psi(x))
	\]
Allora, $\forall x \, x \in B_1 \leftrightarrow (x \in A \land \psi(x)) \leftrightarrow x \in B_2$, quindi, \hyperref[ax2]{estensionalità}, $B_1 = B_2$.
\end{proof}

\begin{exercise}
Verifica che se $\psi \leftrightarrow \Phi$ e $\Phi \leftrightarrow \Theta$, allora $\psi \leftrightarrow \Theta$.
\end{exercise}

\begin{notation}
Vista l'unicità, scriviamo:
\[ B = \{x \in A | \psi(x)\} \Mydef \forall x \, x \in B \leftrightarrow (x \in A \land \psi(x))
	\]
\end{notation}

Osserviamo che l'assioma di separazione è una forma indebolita del principio di collezione. Rimpiazzando questo con quello, il Paradosso di Russell diventa una proposizione.

\begin{proposition}[Insieme di tutti gli inisemi]
Non esiste l'insieme di tutti gli insiemi.
\[ \not\exists V \; \forall x \; x \in V
	\]
\end{proposition}

\begin{proof}
Supponiamo, per assurdo, che esista questo $V$. Allora, per \hyperref[ax3]{separazione} con la formula $\psi (x) \equiv x \not \in x$, esiste:
\[ N = \{x \in V | x \not\in x\}
	\]
che ha, per definizione, la proprietà:
\[ \forall x \, x \in N \leftrightarrow (x \in V \land x \not \in x)
	\]
Per ipotesi assurda, $x \in V$ è sempre vera (stiamo considerando l'insieme di tutti gli insiemi), quindi quanto scritto si riduce a:
\[ \forall x \, x \in N \leftrightarrow x \not\in x
	\]
prendendo ora, $x = N$, abbiamo $N \in N \leftrightarrow N \not\in N$, assurdo.
\end{proof}

\subsection{Classi e classi proprie}
Sebbene, abbiamo detto che gli unici oggetti della teoria degli insiemi sono gli insiemi, usualmente ci si riferisce alla collezione di tutti gli insiemi 
che soddisfano una certa formula come ad una specie di insieme: una \vocab{classe}. Più precisamente, data una formula $\psi(x)$, se diciamo: ``sia $C$ la classe degli insiemi $x$ tali che $\psi(x)$''
intendiamo dire che useremo la scrittura $x \in C$ come una semplice abbreviazione per la formula $\psi(x)$. \\
Non avrebbe senso scrivere \textcolor{red}{$C \in$ qualcosa}, perché il simbolo $\in$ in $x \in C$ non ha senso, se non nel tutt'uno $\in C$. In altri termini, se scriviamo $x \in C$ in luogo di $\psi(x)$ è solo come ausilio dell'intuizione:
avremmo potuto decidere di scrivere $x$\ding{168}, o nient'altro che $\psi(x)$.

\begin{definition}
La classe $V$ si dice \vocab{classe universale} ed è la classe di tutti gli insiemi.
\[ x \in V \Mydef x = x
	\]
\end{definition}

Insomma, scrivere $x \in V$ non dice molto: è una formula sempre vera.
\pagebreak
\begin{notation}
Date due classi $C$ e $D$, che, ricordiamo, non significa altro che ``date due formule$\ldots$'', definiamo l'abbreviazione:
$$ C = D \Mydef \forall x ((x \in C) \leftrightarrow (x \in D)) $$
\end{notation}

Ora, dato un qualunque insieme $A$, possiamo definire la classe $\hat{A}$ degli $x$ tali che $x \in A$. Se $\hat{A} = \hat{B}$, per definizione:
\[ \forall x ((x \in A) \leftrightarrow (x \in B))
	\]
quindi $A = B$ per estensionalità. Ha quindi senso, con un leggero abuso di notazione, omettere il cappelletto $\hat{}$ e identificare la classe $\hat{A}$ semplicemente con $A$. In questo senso,
abbiamo classi che sono insiemi - formalmente $C$ è un insieme se $C = \hat{A}$ per qualche insieme $A$ - e classi che non sono insiemi. Chiamiamo \vocab{classe propria} una classe che non è un insieme.

\begin{example}
$V$ è una classe propria.
\end{example}

\textbf{\underline{L'intuizione}}, che sarà più chiara via via che procediamo nel corso, è che le classi proprie sono troppo grandi per essere insiemi.

\subsection{Assioma del paio e coppia di Kuratowski}
I primi assiomi ci dicono, a grandi linee, che, entro i limiti di quanto si può fare rinunciando al principio di collezione - che esiste $\{x | \, \text{una qualunque proprietà}\}$ -, gli insiemi sono delle specie di collezioni.
Sono determinati dai loro elementi, e li si può dividere in collezioni più piccole in maniera arbitraria. Ci troviamo, però, adesso, nella necessità di procurarci qualche insieme con cui lavorare. I prossimi assiomi serviranno per giustificare le costruzioni con cui,
usualmente, si definiscono nuovi insiemi. Per esempio, abbiamo bisogno di costruire certi insiemi di base, tipo l'insieme dei numeri interi o insiemi finiti i cui elementi sono elencati esplicitamente, fare prodotti di insiemi esistenti, 
considerare le funzioni fra insiemi esistenti, etc.

\begin{axiom}
[Assioma del paio]
\label{ax4}
Dati $a$ e $b$ esiste l'insieme $\{a,b\}$.
\[ \forall a \; \forall b \; \exists P \; \forall x \; x \in P \leftrightarrow (x = a \lor x = b)
	\]
\end{axiom}

\begin{proposition}
[Unicità del paio]
Fissati $a$ e $b$, l'insieme $\{a,b\}$ è univocamente determinato.
\[\forall a \; \forall b \; \exists\textcolor{red}{!} P \; \forall x \; x \in P \leftrightarrow (x = a \lor x = b)
	\]
\end{proposition}

\begin{exercise}
	Dimostra la proposizione precedente.
\end{exercise}

\begin{soln}
	Supponiamo che esistano $P_1$ e $P_2$ tali che:
	\[ \forall x (x \in P_1 \leftrightarrow (x = a \lor x = b)) \qquad \text e \qquad \forall x (x \in P_2 \leftrightarrow (x = a \lor x = b))
		\]
	da ciò segue che:
	\[ \forall x (x \in P_1 \leftrightarrow x \in P_2)
		\]
	dunque per \hyperref[ax2]{estensionalità} $P_1 = P_2$\footnote{Volendo essere pignoli andrebbe specificato $\forall P_1 \, \forall P_2$.}.
\end{soln}

\begin{proposition}[Esistenza dei singoletti]
	Dato $a$, esiste ed è unico $\{a\}$.
	\[ \forall a \; \exists ! S \; \forall x \; x \in S \leftrightarrow x = a
		\]
\end{proposition}

\begin{proof}
	Ponendo $b = a$ nella proposizione precedente, si ha che:
	\[ \forall a \; \exists ! S \; \forall x \; x \in S \leftrightarrow (x = a \lor x= a)
		\]
	ora $x = a \lor x = a$ equivale a $x = a$.
\end{proof}

\begin{notation}
	Possiamo ora porre:
	\[ P = \{a,b\} \Mydef \forall x \, x \in P \leftrightarrow (x = a \lor x = b)
		\]\[ S = \{a\} \Mydef \forall x \, x \in S \leftrightarrow x = a
			\]
\end{notation}

\begin{remark}
	Osserviamo che $\{a,b\} = \{b,a\}$.
\end{remark}

\begin{proof}
	Usiamo il fatto che $\lor$ è commutativo:
	\[ x \in \{a,b\} \leftrightarrow (x = a \lor x = b) \leftrightarrow (x = b \lor x = a) \leftrightarrow x \in \{b,a\}
		\]
	quindi per \hyperref[ax2]{estensionalità} $\{a,b\} = \{b,a\}$.
\end{proof}

Il paio $\{a,b\}$ è, quindi, una coppia non ordinata. È possibile codificare le coppie ordinate con questo trucco.

\begin{definition}
	[Coppia di \href{https://it.wikipedia.org/wiki/Kazimierz_Kuratowski}{\textcolor{purple}{Kuratowski}}]
	Si dice \vocab{coppia di Kuratowski}:
	\[(a,b) \Mydef \{a,\{a,b\}\}
		\]
\end{definition}

\begin{proposition}
	La coppia di Kuratowski $(a,b)$ rappresenta la coppia ordinata di $a$ e $b$, ossia:
	\[ (a,b) = (a^{\prime},b^{\prime}) \leftrightarrow (a = a^{\prime} \land b = b^{\prime})
		\]
\end{proposition}

\begin{proof}
	Dato $c = (a,b)$, vogliamo determinare univocamente $a$ e $b$. Intanto, $a$ è determinato da:
	\[ x = a \leftrightarrow \forall y \in c \,(x \in c)
		\]
	la freccia $\rightarrow$ è immediata [per come è definita $(a,b)$]\footnote{Se $x$ è $a$, allora,
	poiché qualsiasi elemento che appartenga alla coppia o è $\{a\}$ o contiene $a$, $x$ deve appartenere a quest'ultimo.},
	mentre $\leftarrow$ segue da $\{a\} \in c$, per cui $\forall y \in c \, (x \in y) \implies x \in \{a\} \implies x = a$.
	Veniamo ora a $b$. Studiamo prima il caso in cui $\exists ! x \, x \in c$:
	\[ \exists x \, x \in c \iff \{a\} = \{a,b\}
		\]
	in quanto $\{a\} \in c$ e $\{a,b\} \in c$, quindi $\{a\} = \{a,b\} \iff b = a$, per \hyperref[ax2]{estensionalità}. In questo caso, $b$ è quindi determinato.
	Altrimenti, $x = \{a,b\} \leftrightarrow (x \in c \land x \ne \{a\})$, $\{a,b\}$ è quindi univocamente determinato da $c$, e $x = b \leftrightarrow (x \in \{a,b\} \land x \ne a)$.
\end{proof}

\begin{definition}
	Possiamo definire quindi:
	\[ (a,b,c) \Mydef ((a,b),c)
		\]\[ (a,b,c,d) \Mydef (((a,b),c),d)
			\]\[ (a_1,a_2,\ldots,a_n) \Mydef ((a_1,a_2,\ldots,a_{n-1}),a_n)
				\]
\end{definition}

\begin{note}
	Quest'ultima definizione è, in realtà, uno schema di definizioni: una per ogni $n$. Per ora, \textcolor{red}{NON} siamo in grado di scrivere, per esempio,
	una formula insiemistica che dica ``Esiste un $n$ ed una $n$-upla $(a_1,\ldots,a_n)$ tale che…''. Però, per ogni $n$ dato, chessò 92, possiamo scrivere esplicitamente una formula che dice $x = (a_1,a_2,a_3,\ldots,a_{92})$.
\end{note}

\begin{proposition}
	Si ha che:
	\[ (a,b,c) = (a',b',c') \leftrightarrow a = a' \land b = b' \land c = c'
		\]\[ (a_1,\ldots,a_n) = (a_1',\ldots,a_n') \leftrightarrow a_1 = a_1' \land \ldots \land a_n = a_n'
			\]
\end{proposition}

\begin{exercise}
	Dimostra la prima e convinciti che, dato un qualunque $n$ esplicito, potresti dimostrare la seconda.
\end{exercise}

\subsection{Assioma dell'unione e operazioni booleane}

\begin{axiom}[Assioma dell'unione]
	\label{ax5}
	Dato un insieme $A$ esiste un insieme $B$ i cui elementi sono gli elementi degli elementi di $A$. Ovvero, dato un insieme $A$ esiste l'unione degli elementi di $A$.
	\[ \forall A \; \exists B \; \forall x \; x \in B \leftrightarrow \exists y \in A \; x \in y\footnote{Cioè $x$ è un elemento di $B$ se e solo se è un elemento di un elemento di $A$.}
		\]
\end{axiom}

\begin{proposition}
	[Unicità dell'unione]
	Vale l'unicità dell'unione:
	\[ \forall A \; \exists ! B \; \forall x \; x \in B \leftrightarrow \exists y \in A \; x \in y
		\]
\end{proposition}

\begin{proof}
	Supponiamo di avere $B_1$ e $B_2$ tali che:
	\[ \forall x \, x \in B_1 \leftrightarrow \exists y \in A \, x \in y
		\]\[ \forall x \, x \in B_2 \leftrightarrow \exists y \in A \, x \in y
			\]
	quindi $\forall x (x \in B_1 \leftrightarrow x \in B_2)$, e per \hyperref[ax2]{estensionalità} $B_1 = B_2$.
\end{proof}

\begin{notation}
	Possiamo introdurre l'abbreviazione:
	\[ B = \bigcup A\footnote{``Unione di $A$''.} \Mydef \forall x \,( x \in B \leftrightarrow \exists y \, x \in y)
		\]
\end{notation}

\begin{exercise}
	Dimostra che dall'assioma dell'unione segue che:
	\[ \forall A \; \exists B \; (\forall y \in A \; \forall x \in y \; x \in B)\footnote{Cioè per ogni insieme esiste l'insieme di tutti gli elementi degli elementi di $A$.}
		\]
\end{exercise}

Combinando l'assioma dell'unione e del paio possiamo definire $a \cup b$.

\begin{definition}
	Poniamo:
	\[ a \cup b \Mydef \bigcup\{a,b\}
		\]
\end{definition}

\begin{proposition}
	Vale che:
	\[ x \in a \cup b \leftrightarrow (x \in a \lor x \in b)
		\]
\end{proposition}

\begin{proof}
	Dire che $x$ è un elemento di $a \cup b$ significa dire che $x$ è un elemento di un elemento di $\{a,b\}$, ossia
	che $x$ è un elemento di uno fra $a$ e $b$ [il viceversa è ovvio per la definizione che abbiamo dato di unione].
\end{proof}

Ora definiamo le intersezioni: riesci a vedere perché, a differenza delle unioni, non servirà un nuovo assioma?

\begin{definition}
	Sia $C$ una \textcolor{red}{classe}\footnote{Quindi, in particolare, $C$ può essere un insieme (in questo caso la definizione è lecita in generale con le classi, i cui elementi sono insiemi).} non vuota.
	L'\textcolor{red}{insieme} $B$ è l'\vocab{intersezione} di $C$ se:
	\[ B = \bigcap C \Mydef \forall x \; x \in B \leftrightarrow \forall y \in C \; x \in y
		\]
\end{definition}

\begin{proposition}
	Data una classe non vuota $C$, l'intersezione $\bigcap C$ esiste ed è unica. In particolare, nel caso dell'intersezione di un insieme vale:
	\[ \forall A (A \ne \emptyset \rightarrow \exists ! B \; \forall x(x \in B \leftrightarrow \forall y \in A \; x \in y))
		\]
\end{proposition}

\begin{note}
	L'ipotesi $C \ne \emptyset$ è necessaria perché si avrebbe che $\bigcap \emptyset$ è la classe universale $V$, che non è un insieme.
\end{note}

\begin{proof}
	L'unicità segue per \hyperref[ax2]{estensionalità} al solito modo. Veniamo all'esistenza. Dal momento che $C$ non è vuota, possiamo prendere $z \in C$. 
	Ora consideriamo:
	\[ B = \{x \in z | \forall y \in C \, x \in y\}
		\]
	chiaramente $x \in B \rightarrow \forall y \in C \, x \in y$. D'altro canto, $\forall y \in C \, x \in y$ implica, in particolare, $x \in z$, quindi $x \in B$. Abbiamo 
	così verificato che $x \in B \leftrightarrow \forall y \in C \, x \in y$, ossia $B = \bigcap C$.
\end{proof}

\begin{notation}
	Poniamo:
	\[ a \cap b \Mydef \bigcap\{a,b\} \qquad \text e \qquad a\setminus b \Mydef \{x \in a | x \not\in b\}
		\]
\end{notation}

\begin{proposition}
	Vale che:
	\[ x \in a \cap b \leftrightarrow (x \in a \land x \in b)
		\]\[ x \in a \setminus b \leftrightarrow (x \in a \land x \not\in b)
			\]
\end{proposition}

\begin{exercise}
	Dimostrare la proposizione precedente (la seconda è semplicemente la definizione).
\end{exercise}

\begin{proposition}
	Alcune proprietà delle operazioni $\cup$, $\cap$, $\setminus$:
	\[ \text{\textcolor{red}{commutatività:}} \qquad a \cup b = b \cup a \qquad \text e \qquad a \cap b = b \cap a
		\] \begin{align*}	\text{\textcolor{red}{associatività:}} \qquad  
			&a \cup (b \cup c) = (a \cup b) \cup c \Mydef a \cup b \cup c\\
			&a \cap (b \cap c) = (a \cap b) \cap c \Mydef a \cap b \cap c
		\end{align*}
	\begin{align*}	\text{\textcolor{red}{distributività:}} \qquad  
		&a \cup (b \cap c) = (a \cup b) \cap (a \cup c)\\
		&a \cap (b \cup c) = (a \cap b) \cup (a \cap c)
	\end{align*}
	\begin{align*}	\text{\textcolor{red}{leggi di \href{https://it.wikipedia.org/wiki/Augustus_De_Morgan}{\textcolor{purple}{De Morgan}}:}} \qquad  
		&a \setminus (b \cup c) = (a \setminus b) \cap (a \setminus c)\\
		&a \setminus (b \cap c) = (a \setminus b) \cup (a \setminus c)
	\end{align*}
\end{proposition}

\begin{proof}
	Tutte queste proprietà su deducono immediatamente dalle corrispondenti proprietà dei connettivi logici, le quali, a loro volta, si vedono con le tabelle di verità. Per esempio, dimostriamo 
	la prima delle leggi di De Morgan:
	\[ \begin{split}
		x \in a \setminus (b \cup c) & \iff x \in a \land x \not\in (b \cup c)\\
		& \iff x \in a \land \neg(x \in b \lor x \in c)\\
		& \iff x \in a \land x \not\in b \land x \not\in c\\
		& \iff x \in a \land x \not\in b \land x \in a \land x \not\in c\\
		& \iff x \in a \setminus b \land x \in a \setminus c\\
		& \iff x \in (a \setminus b) \cap (a \setminus c)
	\end{split}
		\]
\end{proof}

Ora possiamo costruire insiemi finiti elencandone gli elementi, come si fa di solito, con la notazione $\{\ldots\}$.

\begin{notation}
	Poniamo:
	\[ \{a,b,c\} \Mydef \{a\} \cup \{b\} \cup \{c\}
		\]\[ \{a,b,c,d\} \Mydef \{a\} \cup \{b\} \cup \{c\} \cup \{d\}
			\]\[ \{a_1,\ldots,a_n\} \Mydef \{a_1\} \cup \ldots \cup \{a_n\}
				\]
\end{notation}

\begin{proposition}
	Vale che:
	\[ x \in \{a,b,c\} \leftrightarrow (x = a \lor x = b \lor x = c)
		\]\[ x \in \{a_1,\ldots,a_n\} \leftrightarrow (x = a_1 \lor \ldots \lor x = a_n) 
			\]
\end{proposition}

\begin{exercise}
	Dimostrare la proposizione precedente.
\end{exercise}

\subsection{Assioma delle parti e prodotto cartesiano}
Abbiamo definito le coppie $(x,y)$, però, per esempio, ancora nulla ci assicura che dati $A$ e $B$ esista:
\[ A \times B = \{(x,y) | x \in A \land y \in B\}
	\]
Le funzioni $A \longrightarrow B$ saranno poi sottoinsiemi di $A \times B$, e vorremo parlare dell'insieme ${}^{A}B$
delle funzioni $A \longrightarrow B$. Per tutto questo ci manca un solo ingrediente: l'insieme delle parti.

\begin{axiom}
	[Assioma delle parti]
	\label{ax6}
	Dato un insieme $A$ esiste l'insieme $\ps(A)$ i cui elementi sono i sottoinsiemi di $A$.
	\[ \forall A \; \exists B \; \forall x \; x \in B \leftrightarrow x \subseteq A 
		\]
\end{axiom}

\begin{proposition}
	[Unicità delle parti]
	Vale che:
	\[\forall A \; \exists ! B \; \forall x \; x \in B \leftrightarrow x \subseteq A 
		\]
\end{proposition}

\begin{proof}
	Segue come sempre per \hyperref[ax2]{estensionalità}, in quanto, se avessimo $B_1$, $B_2$, allora:
	\[ \forall x (x \in B_1 \leftrightarrow x \subseteq A) \qquad \text e \qquad \forall x(x \in B_2 \leftrightarrow x \subseteq A)
		\]
	quindi $\forall x(x \in B_1 \leftrightarrow x \in B_2) \leftrightarrow B_1 = B_2$.
\end{proof}

\begin{notation}
	Data l'unicità possiamo porre:
	\[ B = \ps(A) \Mydef \forall x \; x \in B \leftrightarrow x \subseteq A
		\]
\end{notation}

\begin{proposition}[Esistenza ed unicità del prodotto cartesiano]
	Dati $A$ e $B$  esiste un unico insieme $A \times B$ tale che:
	\[ \forall z \; z \in A \times B \leftrightarrow \exists x \in A \; \exists y \in B \; z = (x,y)\footnote{Ossia, informalmente, $A \times B = \{(x,y) | x \in A, y \in B\}$.}
		\]
\end{proposition}

\begin{proof}
	L'unicità è conseguenza immediata della definizione e dell'\hyperref[ax2]{assioma di estensionalità}. Per l'esistenza, definiamo:
	\[ A \times B \Mydef \{z \in \ps(\ps(A \cup B)) | \exists x \in A \ \exists y \in B \ z = (x,y)\}
		\]
	dobbiamo dimostrare che ogni coppia $(x,y)$ con $x \in A$ e $y \in B$ appartiene a questo insieme. Basta dimostrare che tutte queste coppie
	appartengono a $\ps(\ps(A \cup B))$:
	\[\begin{split}
		a \in A \land b \in B &\implies \{a\},\{a,b\} \subseteq A \cup B\footnote{Poniamo $a,b,\ldots \in z \Mydef a \in z \land b \in z \land \ldots$ e $a,b,\ldots \subseteq z \Mydef a \subseteq z \land b \subseteq z \land \ldots$.}\\
		& \implies \{a\},\{a,b\} \in \ps(A \cup B)\\
		& \implies (a,b) = \{\{a\},\{a,b\}\} \subseteq \ps(A \cup B)\\
		& \implies (a,b) \in \ps(\ps(A \cup B))
	\end{split}
		\]
\end{proof}

\begin{note}
	Avremmo potuto costruire $A \times B$ usando, anziché l'assioma delle parti, l'assioma del rimpiazzamento, che vedremo più avanti.
\end{note}

\subsection{Relazioni di equivalenza e di ordine, funzioni}
Ora rivedremo alcuni concetti ben noti dai primi corsi del primo anno (o dalla scuola superiore?). Lo facciamo molto rapidamente, essenzialmente per completezza, e per fissare le notazioni.

\begin{definition}
	Una \vocab{relazione binaria} fra $A$ e $B$ è un sottoinsieme di $A \times B$.
\end{definition}

\begin{notation}
	Data una relazione $\rel \subseteq A \times B$, poniamo:
	\[ a \rel b \Mydef (a,b) \in \rel
		\]
\end{notation}

\begin{example}
	Per esempio scriviamo $a < b$ per $(a,b) \in <$.
\end{example}

\begin{definition}
	Una relazione $\sim \,\subseteq A \times A$ è una \vocab{relazione di equivalenza} se è:
	\begin{enumerate}[(i)]
		\item \textbf{\underline{riflessiva}}: $\forall x \in A \; x \sim x$.
		\item \textbf{\underline{simmetrica}}: $\forall x,y \in A\footnote{$\forall x_1,\ldots,x_n \Mydef \forall x_1 \ldots \forall x_n$, e lo stesso con $\exists$ e con i quantificatori limitati.} x \sim y \leftrightarrow y \sim x$.
		\item \textbf{\underline{transitiva}}: $\forall x,y,z \in A \; (x \sim y \land y \sim z) \rightarrow x \sim z$.
	\end{enumerate}
\end{definition}

\begin{definition}
	$\leq \, \in A \times A$ è una \vocab{relazione di ordine (largo)} se è:
	\begin{enumerate}[(i)]
		\item \textbf{\underline{riflessiva}}: $\forall x \in A \; x \leq x$.
		\item \textbf{\underline{antisimmetrica}}: $\forall x,y \in A \; (x \leq y \land y \leq x) \rightarrow x = y$.
		\item \textbf{\underline{transitiva}}: $\forall x,y,z \in A \; (x \leq y \land y \leq z) \rightarrow x \leq z$.
	\end{enumerate}
\end{definition}

\begin{definition}
	$< \, \in A \times A$ è una \vocab{relazione di ordine stretto} se è:
	\begin{enumerate}[(i)]
		\item \textbf{\underline{irriflessiva}}: $\forall x \in A \; \neg(x < x)$.
		\item \textbf{\underline{transitiva}}: $\forall x,y,z \in A \; (x < y \land y < z) \rightarrow x < z$.
	\end{enumerate}
\end{definition}

\begin{exercise}
	Dimostra che una relazione di ordine stretto $<$ su $A$ è automaticamente asimmetrica:
	\[ \forall x,y \in A \; x < y \rightarrow \neg (y < x)
		\]
\end{exercise}

\begin{proposition}
	Data una relazione di ordine stretto $<$ su $A$, la relazione:
	\[ \leq\, = \{(x,y) \in A \times A | x < y \lor x = y\}\footnote{Formalmente: $\{z \in A \times A | \exists x,y \in A \; z = (x,y) \land \ldots\}$.}
		\]
	è una relazione di ordine largo. Viceversa, se $\leq$ è una relazione di ordine largo, la seguente relazione è dei ordine stretto:
	\[ <\, = \{(x,y) \in A \times A | x \leq y \land x \ne y\}\footnote{Come la nota sopra.}
		\]
	Inoltre, in questo modo, le relazioni di ordine stretto e di ordine largo sono poste in corrispondenza una - a - uno.
\end{proposition}

\begin{proof}
	Definiamo la diagonale:
	\[ \Delta_A \Mydef \{(x,y) \in A \times A | x = y\}
		\]
	Allora è facile verificare che, se $<$ è una relazione di ordine stretto, allora $< \cap \,\Delta_A = \emptyset$ e $< \cup \,\Delta_A$ è una relazione di ordine largo corrispondente.
	Viceversa, se $\leq$ è una relazione di ordine largo, allora $\Delta_A \subseteq \, \leq$ e $\leq \setminus \Delta_A$ è la relazione di ordine stretto corrispondente.
\end{proof}

\begin{notation}
	Fissata una relazione di ordine largo $\textcolor{red}{\leq}$ su $A$, ci sentiremo liberi di usare la corrispondente relazione di ordine stretto $\textcolor{red}{<}$ fintanto che la scelta del simbolo sia indizio sufficiente dell'operazione.
	Inoltre scriveremo $x > y$ per $y < x$ e $x \geq y$ per $y \leq x$.
\end{notation}

\begin{definition}
	Una \vocab{relazione di ordine totale} su $A$ è una relazione di ordine $\leq$ tale che:
	\[ \forall x,y \in A \; x \leq y \; \lor x = y \; \lor y \leq x
		\]
\end{definition}

\begin{exercise}
	Formula la definizione precedente per ordini stretti.
\end{exercise}

\begin{definition}
	Data una relazione $\rel \subseteq A \times B$, $A' \subseteq A$ e $B' \subseteq B$, possiamo definire la \vocab{restrizione} di $\rel$ a $A'\times B'$:
	\[ \rel_{|A' \times B'} \Mydef \rel \cap (A' \times B')
		\]
\end{definition}

\begin{exercise}
	Data $\rel$ relazione di equivalenza/ordine su $A$ e $A' \subseteq A$, dimostra che $\rel_{|A' \times A'}$ è una relazione di equivalenza/ordine su $A'$.
\end{exercise}

\begin{definition}
	Data una relazione $\rel \subseteq A \times B$, definiamo:
	\[ \Dom(\rel) \Mydef \{x \in A | \exists y \in B \; x\rel y\} \qquad \text{\vocab{dominio} di $\rel$}
		\]\[ \Imm(\rel) \Mydef \{y \in B | \exists x \in A \; x \rel y \} \qquad \text{\vocab{immagine} di $\rel$}
			\]
\end{definition}

\begin{definition}
	Chiamiamo \vocab{funzione: $A \longrightarrow B$} una relazione $f \subseteq A \times B$ tale che:
	\[ \forall x \in A \; \exists ! \, y \in B \; (x,y) \in \rel\footnote{Intuitivamente $f$ è l'insieme delle coppie $(x,f(x))$ per $x \in A$.}
		\]
\end{definition}

\begin{notation}
	Data una funzione $f$, scriviamo:
	\[ y = f(x) \Mydef (x,y) \in f
		\]
	Dato $S \subseteq \Dom(f)$, scriviamo:
	\[ f[S] \Mydef \{y \in \Imm(f)| \exists x \in S \; y = f(x)\} = \underbrace{\{f(x) | x \in S\}}_{\text{informalmente}}
		\]
\end{notation}

\begin{definition}
	Una funzione $f: A \longrightarrow B$ è:
	\[ \begin{split}
		\text{\vocab{iniettiva} se:}\; & \forall y \in \Imm(f)\; \exists! \, x \in \Dom(f) \; f(x) = y\\
		\text{\vocab{suriettiva} se:}\; & B = \Imm(f)\; \text{ossia $\forall y \in B \; \exists x \in A \; f(x) = y$.}\\
		\text{\vocab{bigettiva} se:}\; &\text{è sia iniettiva sia surgettiva.}
	\end{split}
		\]
\end{definition}

\begin{definition}
	Data $f$ iniettiva:
	\[ f^{-1} \Mydef \{(y,x) \in B \times A | f(x) = y\}
		\]
\end{definition}

\begin{remark}
	Data $f$ iniettiva, $f^{-1}$ è una funzione: $\Imm(f) \longrightarrow \Dom(f)$ iniettiva.
	In particolare se $f$ è bigettiva: $A \longrightarrow B$, allora $f^{-1}$ è bigettiva.
\end{remark}

\begin{definition}
	Data $f: A \longrightarrow B$ e $A' \subseteq A$:
	\[ f_{|A'} \Mydef \{(x,y) \in A' \times B | f(x) = y\}
		\]
	$f_{|A'}$ ``$f$ \vocab{ristretta} ad $A'$'' è una funzione: $A' \longrightarrow B$.
\end{definition}

\begin{definition}
	Date $g : A \longrightarrow B$ e $f : B \longrightarrow C$:
	\[ f \circ g \Mydef \{(x,z) \in A \times C | z = f(g(x))\}\footnote{O più formalmente $\exists y(y = g(x) \land z = f(y))$.}
		\]
	$f \circ g$, ``$f$ \vocab{composta} con $g$'', è una funzione: $A \longrightarrow C$.
\end{definition}

\begin{notation}
	Indichiamo con $\id_A$ la \vocab{funzione identità su $A$}:
	\[ \id_A \Mydef \{(x,y) \in A \times A | x = y\} \; (= \Delta_A)
		\]
\end{notation}

\begin{remark}
	Data $f : A \longrightarrow B$ bigettiva e $g : B \longrightarrow A$, sono equivalenti:
	\[ g = f^{-1} \qquad g \circ f = \id_A \qquad f \circ g = \id_B
		\]
\end{remark}

\begin{exercise}
	Data $g : A \longrightarrow B$ e $f: B \longrightarrow C$, sotto quali condizioni $f \circ g$ è iniettiva, suriettiva, bigettiva?
\end{exercise}

\begin{exercise}
	Data una relazione di equivalenza $\sim$ su $A$, dimostra che esiste un insieme $\faktor{A}{\sim}$ ed una funzione surgettiva $i_\sim$ da $A$ a $\faktor{A}{\sim}$
	tale che:
	\[ \forall x,y \in A \; x \sim y \leftrightarrow i_\sim(x) = i_\sim(y)
		\]
\end{exercise}

\begin{exercise}
	Data una relazione di equivalenza $\sim$ su $A$ e $f : A \longrightarrow B$, affinché esista $\widetilde{f}: \faktor{A}{\sim} \longrightarrow B$ tale che $f = \widetilde{f} \circ i_\sim$,
	è necessario e sufficiente che $\forall x,y \in A \; x \sim y \rightarrow f(x) = f(y)$.
\end{exercise}

\newpage
\section{Assioma dell'infinito e numeri naturali}
Il nostro prossimo obiettivo è definire i numeri naturali. I soli oggetti della teoria degli insiemi sono gl insiemi, per cui va da sé che 
i numeri saranno determinati insiemi. Il nostro scopo non è quindi tanto definire, quanto codificare i numeri naturali per mezzo di insiemi opportuni.
La scelta della codifica non è obbligata: per esempio potremmo decidere che:
\[ \text{``codifica buffa di $n$''} = \underbrace{\{\{\{\ldots \emptyset\ldots\}\}\}}_{\text{$n$ parentesi}}
	\]
Sceglieremo, invece, quest'altra codifica:
\[ n = \{0,1,\ldots,n-1\} = \{x \in \NN | x < n\}
	\]\[ 0 = \emptyset \qquad 1 = \{0\} \qquad 2 = \{0,1\} \qquad 3 = \{0,1,2\} \qquad \text{etc.}
		\]
che presenta alcuni vantaggi: per esempio $n$ è rappresentato da un insieme di $n$ elementi, e dire $m < n$ equivale semplicemente a dire $m \in n$.\\
L'ostacolo è ora parlare di questi oggetti in maniera precisa nel linguaggio della teoria degli insiemi. A dire il vero, potremmo già scrivere una formula $\Phi(n)$ che dice 
``$n$ è un numero naturale'' si tratta di un \textcolor{red}{esercizio} difficile, che sarà reso più facile da idee che vedremo più avanti. Noi non scriviamo questa formula, ma, anche a farlo,
non potremmo comunque dimostrare che esiste un insieme i cui elementi sono i numeri naturali, questo perché gli assiomi visti finora non permettono di uscire dalla classe degli insiemi finiti (degli insiemi ``ereditariamente finiti'',
ad essere precisi: definiremo questi concetto a tempo debito).\\
Servirà un nuovo assioma. E l'idea da sfruttare è che, siccome $n = \{0,\ldots,n-1\}$, per ottenere il successore di $n$, ossia $n+1 = \{0,\ldots,n-1,n\}$ dobbiamo aggiungere a $n$ l'elemento $n$ stesso: $n+1 = n \cup \{n\}$.
Avendo una formula per denotare il successore, possiamo postulare l'esistenza di un insieme chiuso per successori, e questo ci darà $\NN$.

\begin{definition}
	[Successore]
	Definiamo il \vocab{successore} di $x$:
	\[ s(x) \Mydef x \cup \{x\}
		\]
\end{definition}

\begin{definition}
	[Insiemi induttivi]
	Diciamo che $A$ è un \vocab{insieme induttivo} se contiene $\emptyset$ ed è chiuso per successori, ossia:
	\[ \text{$A$ è induttivo} \iff \emptyset \in A \land \forall x \in A \; s(x) \in A
		\]
\end{definition}

\begin{axiom}
	[Assioma dell'infinito]
	\label{ax7}
	Esiste un insieme induttivo.
	\[ \exists A (\emptyset \in A \land (\forall x \in A \; s(x) \in A))
		\]
\end{axiom}

Finalmente definiamo l'insieme dei numeri naturali - che, per qualche buffa ragione, chiamiamo $\omega$ - come l'intersezione della classe, non vuota per l'assioma dell'infinito,
di tutti gli insiemi induttivi.

\begin{definition}
	L'insieme $\omega$ è l'intersezione di tutti gli insiemi induttivi, ossia $\omega$ è l'unico insieme tale che:
	\[ \forall x (x \in \omega \leftrightarrow(\forall A \; \text{``$A$ è induttivo''}\rightarrow x \in A)) \footnote{Cioè $x$ è in $\omega$ se e solo se è elemento
	di qualsiasi insieme induttivo (nella classe degli insiemi induttivi), e, inoltre, essendo l'intersezione di una classe, è in particolare un insieme (perché per definizione
	stiamo intersecando gli elementi di una classe, che sono insiemi).}
		\]
\end{definition}

Adesso che abbiamo $\omega$, possiamo facilmente dimostrare che ogni dato numero naturale vi appartiene.

\begin{definition}
	Definiamo:
	\[ 0 \Mydef \emptyset \qquad 1 \Mydef s(0) \qquad 2 \Mydef s(1) \qquad 3 \Mydef s(2) \qquad \text{etc.}
		\]
\end{definition}

\begin{exercise}
	Dimostra che $0,1,2,3 \in \omega$.
\end{exercise}

Un esercizio un po' più difficile è esibire insiemi che non appartengono a $\omega$.

\begin{exercise}
	Dimostra che $\{\{\emptyset\}\} \not \in \omega$.\footnote{\textbf{\underline{Idea}}: Esibisci un insieme induttivo che non contiene $\{\{\emptyset\}\}$.}
\end{exercise}

\subsection{Gli assiomi di Peano}
Per convincerci, però, che $\omega$ è, a buon diritto, l'insieme dei numeri naturali, serve qualcosa di più. Classicamente, i numeri naturali si definiscono per mezzo degli
\vocab{assiomi di \href{https://it.wikipedia.org/wiki/Giuseppe_Peano}{\textcolor{purple}{Peano}}}. Questi assiomi, che caratterizzano a meno di isomorfismi l'insieme $\NN$ dotato della funzione di successore, \textbf{per noi diventano dei teoremi} che
dimostreremo a proposito dell'insieme $\omega$. In questo senso, quindi, $\omega$ codifica legittimamente i numeri naturali.

\begin{definition}
	[Assiomi di Peano al secondo ordine (qualunque cosa questo significhi...)]
	Dato un insieme $\NN$, un elemento $0 \in \NN$, e una funzione:
	\[ \text{succ} : \NN \longrightarrow \NN
		\]
	diciamo che $(\NN,0,\text{succ})$ soddisfa gli assiomi di Peano se:
	\begin{enumerate}[(a)]
		\item \label{a}Il successore è iniettivo:
		\[ \forall n,m \in \NN \; \text{succ}(m) = \text{succ}(n) \rightarrow m = n
			\]
		\item \label{b}Lo zero non è un successore:
		\[ \not\exists n \in \NN \; \text{succ}(n) = 0
			\]
		\item \vocab{Principio di induzione}: data una qualunque formula insiemistica (proprietà) $\Phi(n)$ vale:
		\[ (\phi(0) \land \forall n \in \NN \; \Phi(n) \rightarrow \Phi(\text{succ}(n))) \rightarrow \forall n \in \NN \; \Phi(n)
			\]
	\end{enumerate}
\end{definition}

\begin{center}
	\begin{figure*}[h]
		\centering
		\includegraphics[width=10.5cm]{immagini/peano.png}
		\captionsetup{labelformat=empty}
		\caption{Apparivano così in ``\emph{Arithmetices principia}'', nel 1889, gli assiomi di Peano.}
	\end{figure*}
\end{center}

\begin{theorem}
	La funzione $\text{succ}: \omega \longrightarrow \omega$, $\text{succ}(n) = s(n)$, è ben definita e $(\omega,\emptyset,\text{succ})$
	soddisfa gli assiomi di Peano.
\end{theorem}

\begin{proof}
	Per controllare che $\text{succ}$ sia ben definita, occorre assicurarsi che se $n \in \omega$, allora $s(n) \in \omega$. Fissiamo $n \in \omega$
	e consideriamo un qualunque insieme induttivo $A$. Siccome $A$ è induttivo, $\omega \subseteq A$, quindi $n \in A$, e, di conseguenza $s(n) \in A$. Per 
	l'arbitrarietà di $A$, allora, $s(n)$ appartiene a ogni insieme induttivo. Quindi $s(n) \in \omega$.\\
	Dimostriamo ora che $\omega$ rispetta gli assiomi di Peano. Iniziamo con dimostrare (b) e (c), poi passeremo ad (a):
	\begin{enumerate}
		\item[(b)] Supponiamo, per assurdo, $s(n) = \emptyset$. Abbiamo allora:
		\[ n \in n \cup \{n\} = s(n) = \emptyset
			\]
		contro la definizione di $\emptyset$.
		\item[(c)] Dimostriamo che l'insieme $A = \{n \in \omega | \Phi(n)\}$ è induttivo, da cui $\omega = A$\footnote{Stiamo costruendo $A$ come sottoinsieme di $\omega$.}, quindi $\forall n \in \omega \; \Phi(n)$.
		\begin{enumerate}[1.]
			\item Per ipotesi abbiamo che $\Phi(\emptyset)$, quindi $\emptyset \in A$.
			\item $n \in A \underbrace{\implies}_{\text{per ipotesi}} \Phi(n) \implies \Phi(s(n)) \underbrace{\implies}_{\text{perché $n \in \omega \rightarrow s(n) \in \omega$}} s(n) \in A$
		\end{enumerate}
		\item[(a)] La dimostrazione passa attraverso due lemmi.
					\begin{lemma}
					[Lemma 1]
					$\forall n \in \omega \; \bigcup n \subseteq n$.
					\end{lemma}
					\begin{proof}
						Per induzione (c) con $\Phi(n) \Mydef \bigcup n \subseteq n$.
						\[ \Phi(\emptyset): \qquad \bigcup \emptyset = \emptyset \subseteq \emptyset
							\]\[ \Phi(n) \rightarrow \Phi(s(n)): \qquad \bigcup(s(n)) = \bigcup(n \cup \{n\}) = \left(\bigcup n\right) \cup n = n \subseteq s(n)
								\]
						Dove la penultima uguaglianza vale in quanto:
						\[ \begin{split}
							x \in \bigcup(n \cup \{n\}) & \iff \exists y \; x \in y \land y \in n \cup\{n\}\\
														& \iff \exists y \; x \in y \land (y \in n \lor y = n)\\
														& \iff \exists y \; ( x \in y \land y \in n) \lor (x \in y \land y = n)\\
														& \iff \exists y \; ( x \in y \land y \in n) \lor \exists y(x \in y \land y = n)\\
														& \iff x \in \bigcup n \lor x \in N\\
														& \iff x \in \left(\bigcup n\right) \cup n
						\end{split}
							\]
						Mentre l'ultima in quanto, per ipotesi induttiva, $\bigcup n \subseteq n$, quindi $\left(\bigcup n\right) \cup n \subseteq n \cup n = n$.
					\end{proof}
					\begin{lemma}
						[Lemma 2]
						$\forall n \in \omega \; \bigcup s(n) = n$.
					\end{lemma}
					\begin{proof}
						Come nel passo induttivo della dimostrazione precedente:
						\[ \bigcup\left(s(n)\right) = \bigcup (n \cup \{n\}) = \left(\bigcup n\right) \cup n = n
							\]
						dove l'ultima uguaglianza abbiamo $\bigcup n \subseteq n$, non per ipotesi induttiva, ma per il Lemma 1.
					\end{proof}
					Finalmente abbiamo che, per il Lemma 2:
					\[ s(m) = s(n) \implies m = \bigcup s(m) = \bigcup s(n) = n
						\]
	\end{enumerate}
\end{proof}

\subsection{L'ordine di omega}
Conviene, adesso, sviluppare un po' di tecnologia per manipolare i numeri interi. Dopo, dimostreremo altresì che gli assiomi di Peano hanno un unico modello $(\NN, 0, \text{succ})$
a meno di isomorfismi.

\begin{notation}
	Dati $m,n \in \omega$, scriviamo:
	\[ m < n \Mydef m \in n
		\]
\end{notation}

\begin{proposition}
	La relazione $<$ è un ordine totale su $\omega$. 
\end{proposition}

Per dimostrare questa proposizione, sono comodi alcuni lemmi.

\begin{remark}
	Si osserva che:
	\begin{enumerate}[1.]
		\item $m \in n \rightarrow m \in s(n)$, infatti $n \subseteq n \cup \{n\} = s(n)$.
		\item $m \in s(n) \rightarrow (m \in n \lor m = n)$, infatti:
		 \[ \begin{split}
			m \in n \cup \{n\} = s(n) & \iff m \in n \cup \{n\} = s(n)\\
									& \iff m \in n \lor m \in \{n\}\\
									&\iff m \in n \lor m = n
		 \end{split}
			\]
	\end{enumerate}
\end{remark}

\begin{lemma}
	$\forall a,b \in \omega \; a \in b \rightarrow (s(a) \in b \lor s(a) = b)$.
\end{lemma}

\begin{proof}
	Induzione su $b$.
	\begin{itemize}
		\item Caso $b = 0$: $a \in \emptyset \rightarrow \ldots$ vera a vuoto, perché $a \in \emptyset$ è falsa.
		\item Caso $b = s(n)$: l'ipotesi induttiva è $a \in n \rightarrow (s(a) \in n \lor s(a) = n)$. Dobbiamo dimostrare:
		\[ a \in s(n) \rightarrow (s(a) \in s(n) \lor s(a) = s(n))
			\]
		abbiamo che $a \in s(n) \implies a \in n \cup \{n\} \implies a \in n \lor a = n$. Quindi abbiamo due casi:
		\[ \begin{split}
			& a \in n \implies s(a) \in n \lor s(a) = n \implies s(a) \in s(n) \\
			& a = n \implies s(a) = s(n)
		\end{split}
			\]
	\end{itemize}
\end{proof}

Possiamo roa dimostrare la proposizione.

\begin{proof}
	Verifichiamo le tre proprietà richieste da un ordinamento totale:\\
	\textbf{\underline{transitività}}: $a \in b \land b \in c \rightarrow a \in c$. Induzione su $c$:
	\begin{itemize}
		\item \underline{caso $c = 0$}: la premessa $b \in c$ è falsa, quindi l'implicazione è vera a vuoto.
		\item \underline{caso $c = s(n)$}: assumiamo per ipotesi induttiva $a \in b \land b \in n \rightarrow a \in n$. Sapendo $a \in b \land b \in s(n)$
			vogliamo dedurre $a \in s(n)$. Abbiamo due casi:
			\[ \begin{split}
				& b = n \implies a \in b = n \implies a \in s(n)\\
				& b \in n \implies a \in b \in n \implies a \in n \implies a \in s(n)
			\end{split}
				\]
	\end{itemize}
	\textbf{\underline{irriflessività}}: $\neg \,a \in a$. Per induzione:
	\begin{itemize}
		\item \underline{caso $a = 0$}: $\neg \, \emptyset \in \emptyset$ per definizione di $\emptyset$.
		\item \underline{caso $a = s(n)$}: assumiamo l'ipotesi induttiva $\neg \, n \in n$. Per assurdo supponiamo $s(n) \in s(n)$ ed abbiamo due casi:
		\[ \begin{split}
			& s(n) = n \implies n \in n \; \lightning\\
			& s(n) \in n \implies n \in s(n) \in n \implies n \in n \; \lightning
		\end{split}
			\]
	\end{itemize}
	\textbf{\underline{totalità}}: $a \in b \lor a = b \lor b \in a$. Per induzione su $a$:
	\begin{itemize}
		\item \underline{caso $a = 0$}: $\emptyset \in b \lor \emptyset = b \lor b \in \emptyset \footnote{Ovviamente quest'ultimo caso è impossibile.}$. Procediamo per induzione su $b$:
		\begin{itemize}
			\item \underline{caso $b = 0$}: $0 \in \emptyset \lor \emptyset = \emptyset$, dove naturalmente la prima affermazione è falsa, mentre la seconda è vera.
			\item \underline{caso $b = s(m)$}: ipotesi induttiva $\emptyset \in m \lor \emptyset = m$. Abbiamo due casi:
			\[ \begin{split}
				& \emptyset \in m \implies \emptyset \in s(m) \lor \emptyset \in s(m) \implies \emptyset \in b\\
				& \emptyset = m \implies \emptyset \in \{\emptyset\} = s(m) \implies \emptyset \in b
			\end{split}
				\]
		\end{itemize}
	\item \underline{caso $a = s(n)$}: L'ipotesi induttiva è $n \in b \lor n = b \lor b \in n$. Abbiamo tre casi:
		\[ \begin{split}
			& n \in b \implies s(n) \in b \lor s(n) = b \\
			& n = b \implies b \in s(n) \implies b \in a\\
			& b \in n \implies b \in s(n) \implies b \in a 
		\end{split}
			\]
	\end{itemize}
\end{proof}

\begin{corollary}
	Un numero naturale è l'insieme dei numeri naturali minori di lui.
	\[ \forall m \in \omega \; m = \{n \in \omega | n < m\}
		\]
\end{corollary}

\begin{proof}
	Vogliamo dire che $m = \{ n \in \omega | n \in m\}$, ossia che $m \subseteq \omega$. Per induzione: $\emptyset \subseteq \omega$ è vera;
	assumiamo $m \subseteq \omega$, allora $s(m) = m \cup \{m\}$ (con $\{m\} \subseteq \omega$ in quanto $m \in \omega$), quindi $s(m) \subseteq \omega$. %errore di Mamino
\end{proof}

\begin{corollary}
	$\forall m,n \in \omega \; m \leq n \leftrightarrow m \subseteq n$.
\end{corollary}

\begin{proof}
	Siccome $\omega$ è totalmente ordinato, si danno due casi:
	\[ m \leq n \implies \forall x \in \omega \; x < m \rightarrow x < n \implies \forall x \in \omega \; x \in m \rightarrow x \in n \implies m \subseteq n
		\]\[ n < m \implies n \in m \quad \text{tuttavia} \quad n \not\in n \implies m \not\subseteq n
			\]
\end{proof}

\subsection{Induzione forte e principio del minimo}
\begin{theorem}
	[Principio di induzione - forma forte]
	Data una formula insiemistica $\Phi(x)$, vale:
	\[ (\forall n \in \omega (\forall x < n \; \Phi (x)) \rightarrow \Phi(n)) \rightarrow \forall n \in \omega \; \Phi(n)
		\]
	Ovvero, se assumendo $\Phi(x)$ per tutti gli $x < n$, abbiamo $\Phi(n)$, allora $\Phi(n)$ è vera per tutti i numeri $n$.
\end{theorem}

\begin{remark}
	Chiaramente questa forma è ``forte'' perché permette di assumere un'ipotesi induttiva più forte dell'induzione di Peano. In quella, infatti, si deve dedurre $\Phi(n)$ a 
	partire da $\Phi$ del numero precedente. Qui, invece, possiamo far conto di sapere $\Phi$, non solo per il precedente, ma per tutti i numeri minori di $n$.
\end{remark}

\begin{proof}
	Assumiamo vero l'antecedente [e dimostriamo il conseguente]:
	\[ \forall n \in \omega \, (\forall x < n \; \Phi(x)) \rightarrow \Phi(n)
		\]
	Inizialmente, dimostriamo per induzione $\forall m \in \omega \; \psi(m)$ dove:
	\[ \psi(m) \Mydef \forall x < m \; \Phi(x)
		\]
	\begin{itemize}
		\item \underline{caso $m = 0$}: $\forall x < \emptyset \; \Phi(x)$ è vera a vuoto.
		\item \underline{caso $m = s(n)$}: per ipotesi induttiva abbiamo $\forall x < n \; \Phi(x).$ Se $x < m = s(n)$, sappiamo già che $x < n \lor x = n$. Si danno due casi:
		\begin{itemize}
			\item Nel caso $x < n$ abbiamo $\Phi(x)$ per ipotesi induttiva.
			\item Nel caso $x = n$, l'ipotesi induttiva, combinata con l'antecedente ci dà $\Phi(n)$, ossia $\Phi(x)$. Per l'arbitrarietà di $x<m$ abbiamo dimostrato $\forall x < m \; \Phi(x)$.
		\end{itemize}
	\end{itemize}
	Ora sappiamo che $\forall m \in \omega \; \forall x < m \; \Phi(x)$. Dato un $n \in \omega$ qualunque, considerando $m = n + 1$ e $x = n$ otteniamo $\Phi(n)$ (grazie a quanto abbiamo dimostrato).
\end{proof}

\begin{theorem}
	[Principio del minimo]
	Sia $A \subseteq \omega$. Se $A \ne \emptyset$ allora esiste $n \in A$ tale che $\forall x \in A \; n \leq x$. Ovvero, ogni sottoinsieme non vuoto di $\omega$ ha un minimo elemento.
\end{theorem}

\begin{remark}
	[Idea della dimostrazione] Si dimostra per induzione forte che, se $n \in A$, allora $A$ ha un minimo. Poi, siccome $A$ non è vuoto, deve esserci qualche $n \in A$, quindi $A$ ha minimo. L'induzione 
	funziona così. Se $n \in A$, si danno due casi. O esiste $x < n$ con $x \in A$, e allora $A$ ha minimo per ipotesi induttiva, oppure $\forall x < n \; x \not\in A$, ma allora $n$ è il minimo di $A$.
\end{remark}

\begin{proof}
	Considerando la contronominale, dobbiamo dimostrare che se $A$ non ha un minimo elemento, allora $A$ è vuoto.
	Assumiamo quindi $\forall n \in A \; \exists x \in A \; x < n$ (ovvero che $A$ non ha minimo), dobbiamo dimostrare che $\forall n \in \omega \; n \not \in A$ (quindi $A$ vuoto). Procediamo per induzione in forma forte.
	Ci serve dire che $(\forall x < n \; x \not in A) \rightarrow n \not \in A$. QUesto, però, è immediato, perché equivale a:
	\[ \begin{split}
		& (\neg \exists x < n \; x \in A) \rightarrow n \not\in A\\
		\iff &(\neg \exists x < n \land x \in A) \rightarrow n \not\in A\\
		\iff &(\neg \exists x \in A \; x < n) \rightarrow n \not\in A\\
		\iff & n \in A \rightarrow \exists x \in A \; x < n
	\end{split}
		\]
	che è appunto l'assunto.
\end{proof}

\begin{definition}
	Un insieme totalmente ordinato $(S, <)$ si dice \vocab{bene ordinato} se ogni sottoinsieme non vuoto ha un minimo.\footnote{Cioè se vale il principio del minimo.}
	\[ \forall A \subseteq S \; A \ne \emptyset \rightarrow \exists m \in A \; \forall x \in A \; m \leq x
		\]
\end{definition}

La nozione di buon ordine è stata introdotta da Cantor agli albori della teoria degli insiemi, e giocherà un ruolo centrale in questo corso.

\begin{example}
	$(\omega, <)$ è un insieme bene ordinato.
\end{example}

\begin{exercise}
	Dimostra che $X = s(s(s(\omega)))$ è bene ordinato dalla relazione $a < b \Mydef a \in b$.
\end{exercise}

\subsection{Ricorsione numerabile}
La ricorsione è il procedimento per cui si costruisce una funzione $f : \omega \longrightarrow \text{qualcosa}$, definendo $f(s(n))$ a partire da $f(n)$, o,
più in generale da $f(\emptyset),\ldots,f(n)$. Questo è un procedimento fondamentale: potremmo dire che è IL modo di pensare gli infidi puntini ($\ldots$). Vediamo qualche esempio.

\begin{example}
	[Operazioni aritmetiche]
	Possiamo definire somma e prodotto come:
	\[ \begin{cases}
		a + \textcolor{red}{0} = a \\
		a + \textcolor{red}{s(b)} = s(a + b)
	\end{cases}
	\qquad
	\begin{cases}
		a \cdot \textcolor{red}{0} = 0\\
		a \cdot \textcolor{red}{s(b)} = a \cdot b + a
	\end{cases}
		\]
	anziché $a + b = \underbrace{s(s(\ldots a \ldots))}_{\text{$b$ successori}}$ e $a \cdot b = \underbrace{a + a + \ldots + a}_{\text{$b$ volte}}$.
\end{example}

\begin{example}
	[Potenza e fattoriale]
	Possiamo definire ricorsivamente potenze e fattoriali come segue:
	\[ \begin{cases}
		a^{\textcolor{red}{0}} = 1\\
		a^{\textcolor{red}{s(b)}} = a^b \cdot a
	\end{cases}
	\qquad
	\begin{cases}
		\textcolor{red}{0}! = 1\\
		\textcolor{red}{s(a)}! = a! \cdot s(a)
	\end{cases}
		\]
	anziché $a^b = \underbrace{a \cdot a \cdot \ldots \cdot a}_{\text{$b$ volte}}$ e $a! = 1 \cdot 2 \cdot \ldots \cdot (a - 1) \cdot a$.
\end{example}

\begin{example}
	[Sommatoria]
	Possiamo definire la sommatoria come:
	\[\begin{cases}
		\displaystyle
		\sum_{i = 0}^{\textcolor{red}{0}} f(i) = 0\\
		\displaystyle
		\sum_{i = 0}^{\textcolor{red}{s(a)}} f(i) = \left(\sum_{i=0}^{a} f(i) \right) + f(s(a))
	\end{cases}
		\]
	anziché $\displaystyle\sum_{i = 0}^a f(i) = f(0) + f(1) + \ldots + f(a)$.
\end{example}

Altre successioni - \textbf{ossia funzioni con dominio $\omega$} - sono definite nella maniera più naturale proprio per ricorsione.

\begin{example}
	In quanti modi posso coprire una sequenza di $n$ caselle $\underbrace{\square\square\square\ldots\square\square}_{n}$ con tessere di una o due caselle,
	$\square$ e $\square\square$, che non si sovrappongano e non lascino caselle scoperte?
\end{example}

\begin{soln}
	Detto $F_n$ il numero di ricoprimenti di una sequenza lunga $n$, vediamo che la tessera più a sinistra può essere $\square$ o $\square \square$. Nel primo caso, ci sono 
	$F_{n-1}$ modi di completare il ricoprimento, nel secondo caso $F_{n-2}$. Quindi:
	\[ F_n = F_{n-1} + F_{n-2}\footnote{Cioè il numero totale di modi di ricoprire la sequenza di $n$ caselle deriva dalla somma dei due casi, che rappresentano i modi di ricoprire le altre caselle fissata quella/e iniziale/i.}
		\]
	La sequenza risulta completamente determinata, per ricorsione, osservando che $F_0 = F_1 = 1$: sono i numeri di Fibonacci.
\end{soln}

In un certo senso, induzione e ricorsione sono due facce della stessa medaglia: dove l'induzione dimostra $\Phi(s(n))$ assumendo di sapere 
$\Phi(n)$, la ricorsione calcola $f(s(n))$ assumendo di sapere $f(n)$. Lo stesso parallelismo, vedremo, si presenterà per l'induzione e la ricorsione transfinita.
Tornando al numerabile: come abbiamo enunciato due forme dell'induzione, enunceremo due forme della ricorsione.\\
La semplice osservazione che segue dice che due funzioni sono uguali precisamente quando assumono gli stessi valori.

\begin{remark}
	[Estensionalità per funzioni]
	Date $f,g : A \longrightarrow B$, allora:
	\[ f = g \leftrightarrow \forall x \in A \; f(x) = g(x)
		\]
\end{remark}

\begin{proof}
	Si osserva che:
	\[ (x,y) \in f \iff y = f(x) \iff y = g(x) \iff (x,y) \in g
		\]
\end{proof}

\begin{notation}
	Indichiamo con ${}^{A}B$ l'insieme delle funzioni da $A$ a $B$, che esiste per \hyperref[ax3]{separazione} in $\ps(A \times B)$.
\end{notation}

\begin{theorem}
	[Ricorsione numerabile - prima forma]
	\label{ric1}
	Dato un insieme $A$, un elemento $k \in A$ e una funzione:
	\[ h : \omega \times A \longrightarrow A
		\]
	esiste un'unica funzione $f : \omega \longrightarrow A$ tale che:
	\[ \forall n \in \omega \quad f(s(n)) = h(n,f(n))
		\]
\end{theorem}

\begin{example}
	Per definire $a^b$ considero $k = 1$, $h(n,x) = a \cdot x$. Per definire il fattoriale $k = 1$, $h(n,x) = s(n) \cdot x$.
\end{example}

\begin{exercise}
	Come potrei costruire $F_n$ usando questo teorema?
\end{exercise}

\begin{proof}
	Il piano consiste nel trovare una formula $\Phi(x,y)$ che dice ``$y = f(x)$'' - questa è la vera difficoltà 
	della dimostrazione - più semplicemente otteniamo $f$ per separazione nell'insieme $\omega \times A$ usando la formula $\Phi$.
	Per dire ``$y = f(x)$'' dire ``i primi $x$ passaggi della ricorsione, partendo da $k$, conducono a $y$''.\\
	Dato $x \in \omega$ diciamo che $g$ è una \vocab{$x$-approssimazione} se la vale la formula seguente:
	\[ g \in {}^{s(x)}A \land g(\emptyset) = k \land \forall n \in x \; g(s(n)) = h(n,g(n))
		\]
	che dice che $g : \{0,\ldots,x\} \longrightarrow A$ soddisfa la definizione ricorsiva di $f$, ristretta, naturalmente, al dominio $\{0,\ldots,x\}$.
	Il vantaggio di tagliuzzare $f$ in $x$-approssimazioni è che così otteniamo un parametro, $x$, su cui impostare un'induzione.
	\begin{lemma}
		$\forall x \in \omega \; \exists ! \, g$ ``$g$ è una $x$-approssimazione''.
	\end{lemma}

	\begin{proof}
		Induzione su $x$.
		\begin{itemize}
			\item \underline{caso $x = \emptyset$}: Basta osservare che l'unica $\emptyset$-approssimazione è $\{(\emptyset,k)\}$. Infatti il dominio
			è $\{\emptyset\}$ per definizione, e abbiamo la condizione $g(\emptyset) = k$.\\
			\item \underline{caso $x = s(a)$}: Per ipotesi induttiva esiste un'unica \textbf{$a$-approssimazione $g$}. Poniamo:
			\[ g' = g \cup \{(s(a), h(a,g(a)))\}
				\]
			ossia $g'(t) = g(t)$ per $t \leq a$, e $g'(s(a)) = h(a,g(a))$. È immediato verificare che $g'$ è una $s(a)$-approssimazione. Per verificare l'unicità, osserviamo che,
			data $s(a)$-approssimazione $g'$ e $g''$, la loro restrizione a $s(a)$ è una $a$-approssimazione, quindi, per ipotesi induttiva $g'_{|s(a)} = g = g''_{|s(a)}$.
			D'altro canto il dominio di una $s(a)$-approssimazione è $s(s(a)) = s(a) \cup \{s(a)\}$, abbiamo detto che $g'$ e $g''$ coincidono su $s(a)$, e:
			\[ g'(s(a)) = h(a,g'(a)) = h(a,g''(a)) = g''(s(a))
				\]
		\end{itemize}	
	\end{proof}
	Stabilito il lemma, introdurremo la formula $\Phi$:
	\[ \Phi(x,y) \Mydef \exists g \in {}^{s(x)}A \quad \text{``$g$ è una $x$-approssimazione''} \land g(x) = y
		\]
	Per l'unicità della $x$-approssimazione $\forall x \in \omega \; \exists ! \, y \; \Phi(x,y)$, possiamo quindi definire, per ogni $x \in \omega$ e $y \in A$:
	\[ f(x) = y \Mydef \Phi(x,y)\footnote{Formalmente $f = \{(x,y) \in \omega \times A | \Phi(x,y)\}$.}
		\]
	Occorre verificare che $f$ soddisfa le condizioni della ricorsione.
	\begin{itemize}
		\item \underline{$f(\emptyset) = k$}: immediata.
		\item \underline{$f(s(n)) = \ldots$}: Per costruzione $f(s(n)) = g(s(n))$ per una $s(n)$-approssimazione $g$. D'altro canto $g(s(n)) = h(n,g(n))$.
		Ora $g_{|s(n)}$ è una $n$-approssimazione, quindi $g(n) = g_{|s(n)} (n) = f(n)$. Mettendo tutto insieme:
		\[ f(s(n)) = g(s(n)) = h(n,g(n)) = h(n, f(n))
			\]
		L'unicità di $f$ segue facilmente per induzione, Date $f'$ e $f''$ che soddisfano la ricorsione abbiamo:
		\[ f'(\emptyset) = k = f''(\emptyset) \qquad f'(s(n)) = h(n,f'(n)) =\footnote{Per ipotesi induttiva.} h(n,f''(n)) = f''(s(n))
			\]
	\end{itemize}
\end{proof}

Procedendo come negli esempi all'inizio di questa sezione, il \hyperref[ric1]{teorema di ricorsione numerabile} ci consente di costruire le operazioni aritmetiche, le potenze, etc.
A titolo di esempio, vediamo nel dettaglio, il caso della somma.

\begin{example}
	[Costruzione di $+ : \omega \times \omega \rightarrow \omega$]
	Vogliamo formalizzare la definizione:
	\[ \begin{cases}
		a + \textcolor{red}{0} = 0\\
		a + \textcolor{red}{s(b)} = s(a+b)
	\end{cases}
		\]
	Per il \hyperref[ric1]{teorema di ricorsione numerabile} sappiamo che, per ogni $a \in \omega$ fissato, esiste un'unica $f : \omega \rightarrow \omega$ tale che:
	\[ f(\textcolor{red}{0}) = a \land \forall b \in \omega \; f(\textcolor{red}{s(b)}) = s(f(b))
		\]
	Scriviamo quindi:
	\[ a + x = y \Mydef \exists f \in {}^{\omega}\omega \;\; f(0) = a \; \land  \; f(x) = y \; \land \; \forall b \in \omega \; f(s(b)) = s(f(b))
		\]
\end{example}

L'applicazione che segue chiude il conto che abbiamo lasciato aperto con gli assiomi di Peano. Dimostriamo che essi identificano un'unica struttura a meno di isomorfismi, quindi $\omega$ è 
a buon diritto, l'insieme dei numeri naturali.

\begin{theorem}[Unicità dei numeri naturali]
	Supponiamo che $(\NN, 0, \text{succ})$ soddisfi gli assiomi di Peano, allora $(\NN, 0, \text{succ})$ \textbf{e} $(\omega,\emptyset,s)$ sono strutture isomorfe - \textbf{ossia, formalmente, esiste} $f : \omega \longrightarrow \NN$ 
	\textbf{bigettiva tale che} $f(\emptyset) = 0$ e $\forall n \in \omega \; f(s(n)) = \text{succ}(f(n))$.\footnote{Cioè è una bigezione tra insiemi, che rispetta lo 0 e la funzione successore che abbiamo definito.}
\end{theorem}

Fa comodo isolare la seguente osservazione.

\begin{remark}
	$\forall x \in \omega \; x \ne 0 \rightarrow \exists y \in \omega \; x = s(y)$.\footnote{Moralmente, ogni numero diverso da 0 è il successore di qualcos'altro.}
\end{remark}

\begin{proof}
	Induzione su $x$. Il caso $x = 0$ è vero a vuoto (essendo la premessa sempre automaticamente falsa). Nel caso $x = s(m)$ basta prendere $y = m$ e si ha $x = s(y)$.
\end{proof}

Dimostriamo ora il teorema.

\begin{proof}
	Per il \hyperref[ric1]{teorema di ricorsione} c'è un'unica $f$ che soddisfa le condizioni $f(\emptyset) = 0$ e $\forall n \in \omega \; f(s(n)) = \text{succ}(f(n))$.
	Resta da constatare che $f$ è bigettiva.\\
	\textbf{Surgettività} Per ipotesi $(\NN, 0, \text{succ})$ soddisfa il principio di induzione. Dimostriamo quindi per induzione in $(\NN, 0, \text{succ})$ che $\forall y \in \NN \; \exists x \in \omega \; f(x) = y$.
	\begin{itemize}
		\item \underline{caso $y = 0$}: basta osservare che $f(\emptyset) = 0$ per costruzione.
		\item \underline{caso $y = \text{succ}(n)$}: per ipotesi induttiva c'è $x \in \omega$ tale che $f(x) = n$, quindi $f(s(x)) = \text{succ}(n)$.
	\end{itemize}
	\textbf{Iniettività} Consideriamo, per assurdo, il minimo $x \in \omega$ tale che, per qualche $y \in \omega$ con $y \ne x$, $f(x) = f(y)$.
	Osserviamo che, per la minimalità di $x$, $x<y$, quindi, in particolare $y \ne \emptyset$, e possiamo scrivere $y = s(y')$.\\
	\begin{itemize}
		\item Se $x = \emptyset$, allora $\text{succ}(f(y')) = f(s(y')) = f(y) = f(x) = 0$, contraddicendo il \hyperref[b]{(b)} per $(\NN, 0, \text{succ})$.
		\item Se $x \ne \emptyset$ allora possiamo scrivere $x = s(x')$, da cui:
		\[ \text{succ}(f(x')) = f(s(x')) = f(x) = f(y) = f(s(y')) = \text{succ}(f(y'))
			\]
		e, per l'assioma \hyperref[a]{(a)} in $(\NN, 0, \text{succ})$, $f(x') = f(y')$. Allora, per la minimalità di $x$, siccome $x' < x$, dobbiamo avere $x' = y'$.
		Ma da questo seguirebbe $x = s(x') = s(y') = y \; \lightning$.
	\end{itemize}
\end{proof}

Se, infine, volgiamo la nostra attenzione all'esempio dei numeri di Fibonacci, vediamo che non è possibile definire questa sequenza applicando il \hyperref[ric1]{teorema di ricorsione}
in maniera diretta, perché $F_n$ non dispense solo dal termine precedente della sequenza, $F_{n-1}$, ma anche da $F_{n-2}$.\\
Ce la si potrebbe cavare con un trucco, per esempio definendo la funzione $n \longmapsto (F_n,F_{n+1})$ da $\omega$ a $\omega \times \omega$. È comodo, però, disporre di una versione più 
versatile del teorema.

\begin{theorem}
	[Ricorsione numerabile - seconda forma]
	Dato un insieme $A$, denotiamo con $A^*$ l'insieme delle funzioni $g \subseteq \omega \times A$ con $\Dom(g) \in \omega$. Sia $h : A^* \rightarrow A$, allora esiste un'unica funzione
	$f: \omega \rightarrow A$ tale che:
	\[ \forall n \in \omega \; f(n) = h(f_{|n}) \footnote{In altre parole, $f(n)$, può dipendere in maniera arbitraria dai valori assunti da $f$ sui numeri minori di $n$.}
		\]
\end{theorem}

\begin{example}
	[Esempi di applicazione]
	Per costruire la successione di Fibonacci, definiamo $h(g)$ in questo modo. Sia $n = \Dom(g)$. Se $n = \emptyset$ o $n = 1$, allora $h(g) = 1$.
	Altrimenti esistono $n-1, n-2 \in \omega$ tali che $s(n-1) = s(s(n-2)) = n$. Definiamo quindi $h(g) = g(n-1) + g(n-2)$.
\end{example}

\begin{proof}
	L'idea è di definire, mediante la prima forma del \hyperref[ric1]{teorema di ricorsione}, la successione della troncata di $f$. Ossia la funzione $f' : n \longmapsto f_{|n}$. Un modo alternativo, sarebbe 
	ripetere la dimostrazione della prima forma.\\
	Costruiamo per ricorsione - prima forma - la funzione $f' : \omega \rightarrow A^*$ tale che:
	\[ f(\emptyset) = \emptyset \qquad f'(s(n)) = f'(n) \cup \{(n,h(f'(n)))\}
		\]
	Ora poniamo $f(n) = f'(s(n))(n)$. Verifichiamo per induzione che $\forall n \in \omega \; f_{|n} = f'(n)$.
	\begin{itemize}
		\item \underline{caso $n = 0$}: immediato.
		\item \underline{caso $n = s(m)$}: abbiamo:
		\[ \begin{split}
			f_{|s(m)} & = f_{|m} \cup \{(m,f(m))\}\\
					& = f'(m) \cup \{(m,f'(s(m))(m))\}\\
					& = f'(m) \cup \{(m,h(f'(m)))\} = f'(s(m))
		\end{split}
			\]
	\end{itemize}
	Infine, quindi, $f(n) = f'(s(n))(n) = h(f'(n)) = h(f_{|n})$.
\end{proof}

Abbiamo roa terminato di dimostrare le proprietà di base dei numeri naturali. Da qui, prende le mosse il corso di aritmetica. Nella prossima sezione, inizieremo
lo studio di un concetto squisitamente insiemistico: la cardinalità.

\begin{exercise}
	Dimostra commutatività, associatività, etc. di $+$ e $\cdot$.
\end{exercise}

\newpage
\section{Cardinalità}
Il concetto di cardinalità è, forse, il modo più semplice di contare gli elementi di un insieme: diciamo che due insiemi hanno un ugual numero di elementi se esiste
una corrispondenza biunivoca fra di essi.

\begin{definition}
	Dati due insiemi $A$ e $B$:
	\[ |A| = |B| \Mydef \exists f \in {}^A B \; \text{``$f$ è bigettiva $A \longrightarrow B$''}
		\]
	diciamo anche che ``$A$ ha la stessa \vocab{cardinalità} di $B$'' o che ``$A$ e $B$ sono \vocab{equipotenti}''. Poniamo inoltre:
	\[ |A| \leq |B| \Mydef \exists B' \subseteq B \; |A| = |B'| 
		\]
	ossia: $\exists f \in {}^A B$ ``$f$ è iniettiva''.
\end{definition}

\begin{note}
	Osserviamo che:
	\begin{itemize}
		\item La scrittura $|A| = |B|$ suggerisce che esistono insiemi - o oggetti di qualche genere - denotati $|A|$ e $|B|$ di cui si predica l'uguaglianza.
		Effettivamente costruiamo questi oggetti, ma, per ora, la scrittura $|A| = |B|$ è inscindibile, come \ding{168}$[A,B)$.
		\item Potrebbe sorgere il sospetto che se $|A|\textcolor{red}{<}|B|$ quando $A \subsetneq B$, ma non è così, come mostra l'esempio di $A = \{x \in \omega | x > 0\}$ e $B = \omega$.
	\end{itemize}
\end{note}

\subsection{Teorema di Cantor-Berstein}
\newpage
\subsection{Teorema di Cantor}
\newpage
\subsection{Operazioni fra cardinalità}





\newpage
\section{Cardinalità finite}
\subsection{Principio dei cassetti}
\newpage
\subsection{Operazioni fra le cardinalità finite}




\newpage
\section{La cardinalità numerabile}
\subsection{Insiemi numerabili in pratica}
\newpage
\subsection{Prodotto di numerabili è numerabile}
\newpage
\subsection{Numeri interi e razionali}
\newpage
\subsection{Ordini densi numerabili}
\newpage
\subsection{Il grafo random}




\newpage
\section{I numeri reali e la cardinalità del continuo}
\subsection{Caratterizzazione dei reali come ordine}
\newpage
\subsection{La cardinalità del continuo è 2 alla alef-zero}
\newpage
\subsection{Operazioni che coinvolgono la cardinalità del continuo}
\newpage
\subsection{Sottrarre un numerabile dal continuo}




\newpage
\section{Stato del corso}




\newpage
\section{I buoni ordinamenti}
\subsection{Operazioni fra buoni ordinamenti}
\newpage
\subsection{Gli ordinali di Von Neumann}
\newpage
\subsection{Assioma del rimpiazzamento}
\newpage
\subsection{Induzione e ricorsione transfinita}
\newpage
\subsection{Operazioni fra gli ordinali}




\newpage
\section{Aritmetica ordinale e forma normale di Cantor}
\subsection{Sottrazione e divisione euclidea}
\newpage
\subsection{La forma normale di Cantor}
\newpage
\subsection{Punti fissi e epsilon-numbers}
\newpage
\subsection{Operazioni in forma normale di Cantor}
\newpage





\newpage
\section{Gli alef}
\subsection{Teorema di Hartogs}
\newpage
\subsection{Somme e prodotti di alef}



\newpage
\section{L'assioma della scelta}
\subsection{Buon ordinamento implica AC}
\newpage
\subsection{AC implica buon ordinamento (idea)}
\newpage
\subsection{Zorn implica buon ordinamento}
\newpage
\subsection{AC implica Zorn}
\newpage
\subsection{Conseguenze immediate di AC}
\newpage
\subsection{Esempi di applicazione di AC}
\newpage
\subsection{Basi di spazi vettoriali}
\newpage
\subsection{Invariante di Dehn}
\newpage
\subsection{Insieme di Vitali}
\newpage
\subsection{Teorema di Cantor-Bendixson}
\newpage
\subsection{Teorema di Tarski sulla scelta}









\newpage
\section{Aritmetica cardinale}
\subsection{Somme e prodotti infiniti}
\newpage
\subsection{Teorema di König}
\newpage
\subsection{Cofinalità}
\newpage
\subsection{Formula di Hausdorff}






\newpage
\section{Gerarchia di Von Neumann}
\subsection{Formule relativizzate ad una classe}
\newpage
\subsection{Assioma di buona fondazione}
\newpage
\subsection{Principio di epsilon-induzione}


\end{document}
